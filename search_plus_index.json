{"./":{"url":"./","title":"Introduction","keywords":"","body":" 《操作系统真相还原》笔记 通过实践对OS的进一步理解 本项目repo地址：https://github.com/doctording/os 附： Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-02 18:37:10 "},"content/00_cpu/cpu.html":{"url":"content/00_cpu/cpu.html","title":"0 CPU基础","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 CPU常识 CPU整体架构 8086各类寄存器 8086 CPU架构 8086的14个寄存器 数据寄存器 变址和指针寄存器 段寄存器 8086指令和寻址方式 汇编代码中的 eax, ebx, ecx, edx, esi, edi, ebp, esp等 CPU常识 CPU整体架构 cpu整体可分为三部分： 控制单元（CU） 控制单元是整个CPU的指挥控制中心，由程序计数器PC（Program Counter）, 指令寄存器IR(Instruction Register)、指令译码器ID(Instruction Decoder)和操作控制器OC(Operation Controller)等，对协调整个电脑有序工作极为重要。它根据用户预先编好的程序，依次从存储器中取出各条指令，放在指令寄存器IR中，通过指令译码(分析)确定应该进行什么操作，然后通过操作控制器OC，按确定的时序，向相应的部件发出微操作控制信号。操作控制器OC中主要包括节拍脉冲发生器、控制矩阵、时钟脉冲发生器、复位电路和启停电路等控制逻辑。 运算单元（ALU） 是运算器的核心。可以执行算术运算(包括加减乘数等基本运算及其附加运算)和逻辑运算(包括移位、逻辑测试或两个值比较)。相对控制单元而言，运算器接受控制单元的命令而进行动作，即运算单元所进行的全部操作都是由控制单元发出的控制信号来指挥的，所以它是执行部件。 存储单元 包括CPU片内缓存和寄存器组，是CPU中暂时存放数据的地方，里面保存着那些等待处理的数据，或已经处理过的数据，CPU访问寄存器所用的时间要比访问内存的时间短。采用寄存器，可以减少CPU访问内存的次数，从而提高了CPU的工作速度。但因为受到芯片面积和集成度所限，寄存器组的容量不可能很大。寄存器组可分为专用寄存器和通用寄存器。专用寄存器的作用是固定的，分别寄存相应的数据。而通用寄存器用途广泛并可由程序员规定其用途，通用寄存器的数目因微处理器而异。 8086各类寄存器 8086 CPU架构 8086的14个寄存器 数据寄存器 数据寄存器主要用来保存操作数或运算结果等信息，它们的存在节省了为存取操作数所需占用总线和访问存储器的时间。 AX和AL寄存器又称为累加器（Accumulator），使用得比较普遍。 BX寄存器称为基（Base）地址存储器，它是四个数据存储器中唯一可以作为存储器指针使用的存储器。 CX寄存器称为计数（Count）寄存器。在字符串操作和循环操作时，用它来控制重复循环操作次数。在移位操作时，CL寄存器用于保存移位的位数。 DX寄存器称为数据（Data）寄存器。在进行32位的乘除法操作时，用它存放被除数的高16位或余数。它也用于存放I/O端口地址 变址和指针寄存器 变址和指针寄存器主要用于存放某个存储单元地址的偏移，或某组存储单元开始地址的偏移，即作为存储器指针使用。 作为通用寄存器，它们也可以保存16位算术逻辑运算中的操作数和运算结果，有时运算结果就是需要的存储单元地址的偏移。注意，16位的变址寄存器和指针寄存器不能分解成8位寄存器使用。 SI和DI寄存器称为变址寄存器。在字符串操作中，规定由SI（Source Index）给出源指针，由DI（Destination Index）给出目的指针。当然，SI和DI也可作为一般存储器指针使用。 BP和SP寄存器称为指针寄存器。BP（Base Pointer）主要用于给出堆栈中数据区基址的偏移，SP（Stack Pointer）通常只作为堆栈指针使用，即保存堆栈栈顶地址的偏移。 段寄存器 8086/8088 CPU依赖其内部的四个段寄存器实现寻址1M字节物理地址空间（20条地址线）。8086/8088把1M字节地址空间分成若干逻辑段，当前使用段的段值存放在段寄存器中。 CS (Code Segment)：代码段寄存器 DS (Data Segment)：数据段寄存器 SS (Stack Segment)：堆栈段寄存器 ES (Extra Segment)：附加段寄存器 8086指令和寻址方式 一条指令 包括 操作码和操作数 操作码: 表示指令执行什么操作，如mov，add，sub等等 操作数：参加操作的数或数的存放地址（寄存器，各种地址表示格式） 寻找操作数存放的地址称为寻址方式，可分为如下几类 立即寻址方式 MOV AL，06H 寄存器寻址方式 MOV BX，AX 直接寻址方式 MOV BX, DS:[2000H] 操作数存放在存储器中, 偏移量直接写在操作数中,. 地址为数据段寄存器DS的值* 16 ( 寄存器间接寻址方式 操作数存放在存储器中, 16位偏移地址存放在SI, DI, BP, BX四个寄存器之一中. 若使用BX, SI, DI之一作为寄存器, 操作数默认放在DS所决定的数据段中. 即地址为:DS *16 + BX 示例: MOV AX, [SI] ; 将DS*16 + SI中的值放入AX中 若使用BP做间接寻址, 操作数默认放在SS决定的堆栈段中. 示例: MOV AX, [BP] ;将SS*16 + BP中的值放入AX中 可以直接指定使用的段寄存器: MOV AX, SS:[SI] ;将SS*16 + SI中的值放入AX中 寄存器相对寻址方式 操作数存放在存储器中, 使用段寄存器内容* 16 加SI, DI, BP, BX四个寄存器之一的内容再加直接给出的位移量. 若使用BX, SI, DI之一作为寄存器, 操作数默认放在DS所决定的数据段中; 若使用BP做间接寻址, 操作数默认放在SS决定的堆栈段中. 与寄存器间接寻址相比只是增加了直接给出的偏移量: 示例: MOV AX, [SI-2] ; 将 DS*16 + SI - 2中的值放入AX中 MOV AX, [BP+4] ;将 SS*16 + BP + 4中的值放入AX中 MOV AX, SS:[SI-8] ;将 SS*16 + SI - 8中的值放入AX中 基址变址寻址方式 将段地址寄存器的值*16加上基址寄存器(BX,BP)之一的地址加上变址寄存器(SI, DI)之一的值作为地址. 若使用BX作基址 操作数默认放在DS所决定的数据段中; 若使用BP做基址, 操作数默认放在SS决定的堆栈段中. 示例: MOV AX, [BX][SI] ; 将 DS*16 +BX + SI中的值放入AX中 MOV AX, [BP][DI] ;将 SS*16 + BP + DI 中的值放入AX中 MOV AX SS:[Bx][SI] ;将 SS*16 + BX + SI 中的值放入AX中 相对基址变址寻址方式 在基址变址寻址基础上再加一个直接给出的偏移量： 示例： MOV AX, 1234H[BX][DI]　;将DS * 16 + BX + DI + 1234H中的值放入AX中. 还有几种表示方法与上式等价: MOV AX, [BX+DI+1234H] MOV AX, 1234H[BX+DI] MOV AX, 1234H[BX][DI] 汇编代码中的 eax, ebx, ecx, edx, esi, edi, ebp, esp等 EAX 是\"累加器\"(accumulator), 它是很多加法乘法指令的缺省寄存器。 EBX 是\"基地址\"(base)寄存器, 在内存寻址时存放基地址。 ECX 是计数器(counter), 是重复(REP)前缀指令和LOOP指令的内定计数器。 EDX 则总是被用来放整数除法产生的余数。 ESI/EDI分别叫做\"源/目标索引寄存器\"(source/destination index),因为在很多字符串操作指令中, DS:ESI指向源串,而ES:EDI指向目标串. EBP是\"基址指针\"(BASE POINTER), 它最经常被用作高级语言函数调用的\"框架指针\"(frame pointer). 在破解的时候,经常可以看见一个标准的函数起始代码: push ebp ;保存当前ebp mov ebp,esp ;EBP设为当前堆栈指针 sub esp, xxx ;预留xxx字节给函数临时变量. ESP 专门用作堆栈指针，被形象地称为栈顶指针，堆栈的顶部是地址小的区域，压入堆栈的数据越多，ESP也就越来越小。在32位平台上，ESP每次减少4字节。 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-12-22 12:42:19 "},"content/00_cpu/call_ret.html":{"url":"content/00_cpu/call_ret.html","title":"call和ret指令","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 call ret指令 汇编程序 内存栈和call指令 执行栈的变化分析 ret指令 call ret指令 汇编程序 windows平台下的c程序 int fun(int a, int b) { a += 1; b *= 2; int c = a + b; return c; } int main() { int a = 1; int b = 2; int c = fun(a, b); printf(\"%d\\n\", c); return 0; } 汇编程序 int main() { 00938270 push ebp 00938271 mov ebp,esp 00938273 sub esp,0E4h 00938279 push ebx 0093827A push esi 0093827B push edi 0093827C lea edi,[ebp-0E4h] 00938282 mov ecx,39h 00938287 mov eax,0CCCCCCCCh 0093828C rep stos dword ptr es:[edi] int a = 1; 0093828E mov dword ptr [a],1 int b = 2; 00938295 mov dword ptr [b],2 int c = fun(a, b); 0093829C mov eax,dword ptr [b] 0093829F push eax 009382A0 mov ecx,dword ptr [a] 009382A3 push ecx 009382A4 call fun (93710Dh) 009382A9 add esp,8 009382AC mov dword ptr [c],eax printf(\"%d\\n\", c); 009382AF mov eax,dword ptr [c] 009382B2 push eax 009382B3 push offset string \"%d\" (983EE8h) 009382B8 call @ILT+3880(_printf) (936F2Dh) 009382BD add esp,8 return 0; 009382C0 xor eax,eax } 内存栈和call指令 注意到：函数调用一定是call指令 009382A4 call fun (93710Dh) 注意到call指令之前的一些指令: 是参数入栈，而且是从右到左的顺序 0093829C mov eax,dword ptr [b] 0093829F push eax 009382A0 mov ecx,dword ptr [a] 009382A3 push ecx CALL指令（\"调用\"指令）的功能，就是以下两点： 将下一条指令的所在地址（即当前程序计数器PC的内容）入栈（理解为保护当前线程栈） 并将子程序的起始地址送入PC（于是CPU的下一条指令就会转去执行子程序） 执行栈的变化分析 在main线程栈中，将参数压入，并将call指令下一条指令所在地址也压入栈 call之后，debug就能进入fun函数里面，此时的操作时push ebp 这是保存上一个函数栈的ebp, 也就是保存main函数栈，可以发现main函数开头也是这一句。（所以，每个函数都有自己的函数栈，但都是在整个内存栈中） push指令后，esp是自动往下移动了的，这一个是把当前的esp赋值给ebp（所以，main函数的ebp，保存了的，这里ebp变化了，也就形成了fun函数自己的函数栈了） mov ebp,esp sub esp,0CCh sub操作是给当前函数分配栈大小的初始空间 接着进入到fun函数栈了 return return c; 011C8248 mov eax,dword ptr [c] } 011C824B pop edi 011C824C pop esi 011C824D pop ebx 011C824E mov esp,ebp 011C8250 pop ebp 011C8251 ret return语句，可以看到最后的返回结果存到了eax中, fun函数的最后3条指令 011C824E mov esp,ebp 011C8250 pop ebp 011C8251 ret mov esp, ebp就是清除fun的函数栈，现在esp指向了ebp（ebp就是原来fun函数的栈底地址） pop ebp就是弹出main函数的ebp 即如下的1,2操作，接着函数栈变成了，如下图红色框里面的内容： ret指令 ret指令用栈中的数据，修改IP的内容，从而实现近转移； CPU执行ret指令时，进行下面的两步操作： (IP) = ((ss)*16 +(sp)) (sp) = (sp)+2 经过上面的两条语句后，esp指向了 上图中[call指令下一个指令的所在地址] 那里， IP刚好取得地址，然后回到原来，main函数的地方 接着 esp 增加，也就是出栈，所以 main函数栈如下 回到main函数中 011C82A4 call fun (11C710Dh) 011C82A9 add esp,8 011C82AC mov dword ptr [c],eax printf(\"%d\\n\", c); 011C82AF mov eax,dword ptr [c] 011C82B2 push eax 011C82B3 push offset string \"%d\" (1213EE8h) 011C82B8 call @ILT+3880(_printf) (11C6F2Dh) 011C82BD add esp,8 call指令之后是add esp 8操作，这是因为有两个参数，所以add esp 8 ，弹出两个int参数 mov dword ptr [c],eax操作则是把fun函数返回结果存储到变量c中，即函数调用完后，一切恢复正常（fun函数栈已经被清除掉了）；回到main的函数栈中，即如下图 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-10-10 20:48:16 "},"content/00_cpu/cpu_time.html":{"url":"content/00_cpu/cpu_time.html","title":"CPU周期指令","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 CPU指令相关 指令周期 CPＵ周期 时钟周期 周期关系 常见问题：移位运算为什么比乘法除法快？ 指令流水线 CPU指令相关 指令周期 指令周期：是指计算机从取指到指令执行完毕的时间 计算机执行指令的过程可以分为以下三个步骤： Fetch（取指），也就是从 PC 寄存器里找到对应的指令地址，根据指令地址从内存里把具体的指令，加载到指令寄存器中，然后把 PC 寄存器自增，好在未来执行下一条指令。 Decode（译码），也就是根据指令寄存器里面的指令，解析成要进行什么样的操作，是 R、I、J 中的哪一种指令，具体要操作哪些寄存器、数据或者内存地址。 Execute（执行指令），也就是实际运行对应的 R、I、J 这些特定的指令，进行算术逻辑操作、数据传输或者直接的地址跳转。 CPＵ周期 CPU周期亦称机器周期，在计算机中，为了便于管理，常把一条指令的执行过程划分为若干个阶段，每一阶段完成一项工作。 例如，取指令、存储器读、存储器写等，这每一项工作称为一个基本操作（注意：每一个基本操作都是由若干CPU最基本的动作组成）。完成一个基本操作所需要的时间称为机器周期。通常用内存中读取一个指令字的最短时间来规定CPU周期。 时钟周期 时钟周期也称为振荡周期，定义为时钟频率的倒数。时钟周期是计算机中最基本的、最小的时间单位。在一个时钟周期内，CPU仅完成一个最基本的动作。 周期关系 常见问题：移位运算为什么比乘法除法快？ 因为移位指令(单周期指令)占2个机器周期，而乘除法指令占4个机器周期。从硬件上看，移位对硬件更容易实现；所以从效率上看，使用移位指令有更高的效率。 指令流水线 指令的二级流水 指令的6级流水 取指FI:从存储器取出一条指令放入指令部件缓冲区 指令译码DI:确定操作性质和操作数地址形成方式 计算操作数地址CO:计算操作有效地址 取操作数FO:从存储器中取出操作数 执行指令EI:执行指令，将结果存入目的位置 写操作书WO:将结果存入寄存器 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-10-11 09:54:38 "},"content/01_BIOS_to_MBR/":{"url":"content/01_BIOS_to_MBR/","title":"1 最简单的OS:实模式下BIOS到MBR","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 BIOS到MBR 编写主引导程序，运行最基础的操作系统，直接实践 mbr.S文件编写，编译和磁盘文件创建 windows下在VMware虚拟机上运行OS 知识问题总结 实模式下1MB内存布局 程序载入内存 内存和总线 BIOS加载 MBR(主引导记录,Master Boot Record)的加载 参考 Linux下dd命令的使用 汇编--INT 10H功能 BIOS到MBR 编写主引导程序，运行最基础的操作系统，直接实践 mbr.S文件编写，编译和磁盘文件创建 Linux确保可以汇编（安装nasm），新建一个空目录，包含mbr.S和Makefile代码见相应的code文件夹 $make build $make image 这样可以生成.bin代码文件和.img的镜像文件(注意观察各文件大小) 查看镜像文件内容 windows下在VMware虚拟机上运行OS 需要使用软盘 运行图 知识问题总结 基础知识 汇编基础 8086 16位CPU寄存器，地址总线（20根） 实模式内存地址访问（段地址：偏移） 实模式下1MB内存布局 http://book.51cto.com/art/201604/509566.htm 程序载入内存 程序被加载器（软件或硬件）加载到内存的某个区域 CPU的cs寄存器:ip寄存器被指向这个程序的起始地址(CS为代码段寄存器，IP为指令指针寄存器) 内存和总线 DRAM是插在主板上的内存条 ，这种动态随机访问内存需要定期刷新，其电容小，易漏电，需要补电，即数据是可擦除的； 插在主板上的内存条需要通过地址总线访问（地址总线条数，决定了可以访问到的物理内存的大小） CPU访问一个地址，是总线来做映射的，相当于给地址分配一个存储单元，这个存储单元会落在某个rom中，某个外设的内存中，物理内存条上。 BIOS加载 BIOS是一个软件，由一个硬件加载，这个硬件是一个只读存储器ROM(只读存储器是不可擦除的，数据被写入后，掉电也不会丢失数据) 机器加电时，CPU发出的地址被传递到南桥并由FHW(Firmware Hub)解码到BIOS ROM芯片(Flash)。在加电时一直到引导进程初，BIOS的E段(0xE0000~0xEFFFF)和F段(0xF0000~0xFFFFF)和4G内存顶端的对应0xFFFE0000~0xFFFEFFFF和0xFFFF0000~0xFFFFFFFF都被FWH解码到BIOS的ROM芯片的两个64区域。即在启动阶段访问0xE0000~0xEFFFF和0xFFFE0000~0xFFFEFFFF是同一个BIOS区域，访问0xF0000~0xFFFFF和0xFFFF0000~0xFFFFFFFF是同一个BIOS区域。 机器加电时，进入的实模式，CPU访问CS*16+EIP这个地址，CS段寄存器值为0xF000,EIP值为0x0000FFF0，所以机器启动时CPU将访问0xFFFF0(该地址为BIOS入口地址)，实模式下1M地址中的0xF0000-0xFFFFF这个内存地址就是ROM,其存储的就是BIOS代码（16字节大小：JMP F000:E05B），接着CPU执行地址为0xFE05B中的指令，而系统 BIOS 范围是 F0000～FFFFF共640KB，此属于BIOS代码，为BIOS程序的真正内容。 BIOS本身是个程序，其所作的工作一般也是不变的，一般不需要修改。主要工作是检测、初始化硬件，怎么初始化的？硬件自己提供了一些初始化的功能调用， BIOS 直接调用就好了。 BIOS 还做了一件伟大的事情，建立了中断向量表，这样就可以通过“中断号”来实现相关的硬件调用，当然 BIOS 建立的这些功能就是对硬件的I/O操作，也就是输入输出，但由于只有64KB大小的空间，不可能把所有硬件的I/O操作实现得面面俱到，而且也配必要实现那么多，毕竟是在实模式之下，对硬件支持得再丰富也自搭，精彩的世界是在进入保护模式以后才开始，所以挑一些重要的、保证计算机能运行的那些硬件的基本I/O操作，就行了。这就是 BIOS 称为基本输入输出系统的原因 。 BIOS执行完后，最后一项工作校验启动盘中位于0盘0道1扇区的内容（即为MBR） MBR(主引导记录,Master Boot Record)的加载 MBR大小512字节，最后有两字节0x55，0xaa，这称为魔数 MBR程序段入口地址为0x7c00，（由于IBM个人PC等历史原因设置的），所以可以看到SECTION MBR vstart=0x7c00的设置 将硬盘的0盘0道1扇区填充为MBR程序的内容，然后给计算机配置此硬盘为启动盘。这样计算机启动时，就能够从BIOS到MBR了 参考 图书 《操作系统真相还原》 Linux下dd命令的使用 http://www.cnblogs.com/gotopower/articles/4378199.html 汇编--INT 10H功能 http://www.cnblogs.com/magic-cube/archive/2011/10/19/2217676.html Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-28 13:55:38 "},"content/02_mbr_hd/":{"url":"content/02_mbr_hd/","title":"2 让MBR操作硬盘，在内存中操作数据显示（显示不再是BIOS中断，而是直接操作1M的显示文本内存）","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 让MBR直接操作硬盘，对硬盘进行读写操作 环境 代码编写 运行虚拟机 分析 首先硬盘结构如下 实模式下的1MB内存布局 参考 x86 显示相关 让MBR直接操作硬盘，对硬盘进行读写操作 上一步成功进入MBR了，这样MBR的功能就能丰富下去 硬盘概念：柱面，磁道，扇区 环境 ubuntu14-32bit bochs-2.4.5 注：ubuntu安装bochs如果有问题，可自行搜索解决 代码编写 代码目录相应的code文件夹 需要自己修改Makefile,生成的目录可自行设定 通过bximage来制作硬盘 在配置bochs文件时，根据需要配置，具体见code/bochsrc.dist文件 bochs模拟了硬件 这里需要添加从硬盘启动的，硬盘信息 ata0-master: type=disk, mode=flat, path=\"/home/john/os/hd30M.img\", cylinders=60, heads=16, spt=63 运行虚拟机 制定配置文件运行 $bochs -f bochsrc.dist 按6开始模拟 再按c运行起来 遇到模拟器卡死情况，kill杀死 分析 首先硬盘结构如下 实模式下的1MB内存布局 http://book.51cto.com/art/201604/509566.htm 硬盘当成一个IO设备，其有硬盘控制器（I/O接口）,就像显示器一样，其有显卡（也称为显示适配器），显存 我们操作了 用于文本模式显示适配器 ，其在1M物理地址下的开始地址是 0xB8000（有32KB大小）。 首先需要明确：对0xb8000这个内存地址写入内容，就可以在屏幕上输出文本; 本例我们使用gs寄存器存储了0xb8000这个地址，loader则存到磁盘的第2扇区，其操作了gs寄存器; mbr操作磁盘第二扇区（即loader），读取的内容存到0x900这个内存地址中; 此后，当mbr jmp到0x900这个内存地址时，就会执行0x900这块内存的指令，也就是是loader中的内容，也就是操作0xb8000这个内存地址，也即向屏幕中显示文本。 参考 x86 显示相关 http://blog.csdn.net/longintchar/article/details/70183677 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-02 12:46:25 "},"content/03_protected_mode/":{"url":"content/03_protected_mode/","title":"3 实模式到保护模式（分段)","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 进入保护模式 实模式下的一些问题？ 分段基础和如何分段 分段概述 如何分段 物理内存地址如何确定？ 本次分段代码讲解 boot.inc 分析 全局描述符表(GDT)的构造 实模式到保护模式的设置和跳转 保护模式代码执行 进入保护模式 实模式下的一些问题？ 实模式下操作系统和用户程序属于同一特权级，没有区别 逻辑地址就是物理地址 用户程序可以修改段基址，内存所有地址都能够访问到 20根地址线，最大内存1M, 太小 一次只能运行一个程序 实模式下采用：物理地址 = 基础地址(段基址偏移4位) + 偏移地址来访问内存，对x8616位寄存器最大是2^16=64KB，即当访问的内存超过64KB时，就要更改段基址了（即如果使用16bit段寄存器CS（Code Segment），DS（Data Segment），SS（Stack Segment）来指定段，CPU将段寄存器中的数值向左偏移4bit，放到20bit的地址总线上就成为20bit的Base Address，在加上偏移地址构成实际对物理地址） 因为这些问题，所以有了保护模式，保护模式可以做到如下： 地址线32根，最大内存可以是4G 32位寄存器，是可以访问到4G内存的 分段基础和如何分段 分段概述 80386/80486 CPU 共有3 种描述符表：全局描述符表(GDT)、局部描述符表(LDT)和中断描述符表(IDT)。描述符表由描述符顺序排列组成，占一定的内存，由系统地址寄存器(全局描述符表寄存器:GDTR 、局部描述符表寄存器:LDTR、中断描述符表寄存器:IDTR) 指示其在物理存储器中的位置和大小. 全局描述符表寄存器GDTR，48位寄存器 中断描述符表寄存器IDTR，48位寄存器 局部描述符表寄存器LDTR，16位寄存器 GDT是全局描述表，主要存放操作系统和各任务公用的描述符，如公用的数据和代码段描述符、各任务的TSS描述符和LDT描述符。（TSS是任务状态段，存放各个任务私有运行状态信息描述符） LDT是局部描述符表，主要存放各个任务的私有描述符，如本任务的代码段描述符和数据段描述符等(在分页机制出现以前的操作系统中并没有虚拟内存（Virtual Memory）这个概念;为了让不同程序的数据彼此互不干扰，x86架构引入了LDT概念，期望操作系统可以通过为不同的应用程序设置不同的LDT而隔离程序间的数据。) 保护模式下的段寄存器 由 16位的选择器 与 64位的段描述符寄存器 构成 原先实模式下的各个段寄存器作为保护模式下的段选择器，80486中有6个(即CS,SS,DS,ES,FS,GS)段寄存器。由选择器CS对应表示的段仍为代码段，选择器SS对应表示的段仍为堆栈段。 这些16bit的段寄存器也成为段选择子（Selector），描述如下 描述符索引——用来在描述符表中选择一个段描述符,2^13=8196个段（系统中就是8196个段描述符） 描述符表指示器——TI=0时，在GDT表中；TI=1时，在LDT表中 请求特权级别——4个级别，0，1，2，3 如何分段 首先,保护模式下使用分段模式，访问一个内存地址仍然使用Segment:Offset的方式，不过要能支持访问到32bit的地址，即4GB内存 其次，段访问提供了保护机制，也就说一个段的描述符中需要规定对自身的访问权限（Access）。所以，在保护模式下，对一个段的描述则包括3方面因素：[Base Address, Limit, Access]，它们加在一起被放在一个64bit(8字节)长的数据结构中，即为段描述符 基地址Base Address分散在这64bit中，整体是32bit的，即确保了能访问整个4GB内存 描述符类型标志S，可以描述段类型：系统段，数据段，代码段等 段限长Limit分散在这64bit中，整体是20bit的，当颗粒度G=0时，Limit值的单位是B，即Limit的范围可以是1B到1MB；当G=1，则Limit值的单位是4KB，即Limit的范围可以是4KB到4GB，即确保了能访问整个4GB内存 GDTR寄存器48bit，32bit描述了在GDT在内存中的起始地址(GDT存放在内存中的某个任意位置，通过GDTR的这32bit先定位到在内存那里，然后才能定位到具体的段描述符号)；16bit限长（2^16=65536)(8196个段描述符 每个段描述符是8字节，2\b^13 2^3 = 2^16)，所以16bit限长，13bit索引，8196个段描述符，段描述符大小是8字节，这些都是完美的设计数字 物理内存地址如何确定？ 段寄存器的TI=1的内存访问： 先从全局描述符表寄存器(GDTR)寄存器(48位,其中前32位base+16位长度)中获得全局描述符表(GDT)基址 从LDTR寄存器中获取LDT所在段的位置索引(LDTR的高13位) 根据1，2确定GDT中具体的段描述符，即定位到具体的LDT段基址 由段选择子的高13位位置索引值再从LDT段中定位到具体LDT段描述符 段描述符中包含段的基址、限长、优先级等各种属性；这就得到了段的起始地址（基址），再加上偏移地址，就能得到最终的物理内存地址 举例说明物理内存的定位 访问ds:0x9这样的内存 若选择子（段寄存器）的内容是:0x8，如下所示 0000 0000 0000 1000 描述符索引值：0000 0000 0000 1，(结合TI, 则对应GDT中的第一个描述符） TI: 0 (表示使用了GDT, 而非LDT) RPL: 00 假设第一个段描述符的所有32bit的基址起来后的内容是0x1234，则段基址确定为:0x1234 最后访问的内存地址是0x1234:0x9，即0x123d 注意：选择子如果忘记初始化，那个将访问第0个描述符，所以GDT第0个描述符不可用。若选择到了第0个描述符，则处理器会发生异常。 本次分段代码讲解 代码见相应的code文件夹 上一章节的代码若没有问题，这次mbr.S不需要修改，唯一的修改就是读入的扇区数要变大，原来只有一个第2扇区，现在利用磁盘读写第2,3,4,5四个扇区（这当然是可变的）。 需要弄清楚这4个扇区究竟存了些什么东西；显然要是保护模式，则需要有：GDT，段描述符，选择子等，内存不再是直接的“段基址：偏移量”直接访问了，而是通过段描述符定位基址，然后“基址：偏移量”访问 boot.inc 分析 ;------------- loader和kernel ---------- LOADER_BASE_ADDR equ 0x900 LOADER_START_SECTOR equ 0x2 ;-------------- gdt描述符属性 ------------- DESC_G_4K equ 1_00000000000000000000000b DESC_D_32 equ 1_0000000000000000000000b DESC_L equ 0_000000000000000000000b ; 64位代码标记，此处标记为0便可。 DESC_AVL equ 0_00000000000000000000b ; cpu不用此位，暂置为0 DESC_LIMIT_CODE2 equ 1111_0000000000000000b DESC_LIMIT_DATA2 equ DESC_LIMIT_CODE2 DESC_LIMIT_VIDEO2 equ 0000_000000000000000b DESC_P equ 1_000000000000000b DESC_DPL_0 equ 00_0000000000000b DESC_DPL_1 equ 01_0000000000000b DESC_DPL_2 equ 10_0000000000000b DESC_DPL_3 equ 11_0000000000000b DESC_S_CODE equ 1_000000000000b DESC_S_DATA equ DESC_S_CODE DESC_S_sys equ 0_000000000000b DESC_TYPE_CODE equ 1000_00000000b ;x=1,c=0,r=0,a=0 代码段是可执行的,非依从的,不可读的,已访问位a清0. DESC_TYPE_DATA equ 0010_00000000b ;x=0,e=0,w=1,a=0 数据段是不可执行的,向上扩展的,可写的,已访问位a清0. DESC_CODE_HIGH4 equ (0x00 将如下的地址对应到段描述符的高32位中的0-23位 G位: G=1 代表段基址的粒度是4KB DESC_G_4K equ 1_00000000000000000000000b D位:分D和B: 1是D,代表数据段;0是B，代表堆栈段 DESC_D_32 equ 1_0000000000000000000000b type 选择子属性，选择子定义在loader.S中：16位，可以索引到具体的段描述符 全局描述符表(GDT)的构造 定义4个段描述符 ;构建gdt及其内部的描述符 GDT_BASE: dd 0x00000000 dd 0x00000000 CODE_DESC: dd 0x0000FFFF dd DESC_CODE_HIGH4 DATA_STACK_DESC: dd 0x0000FFFF dd DESC_DATA_HIGH4 VIDEO_DESC: dd 0x80000007 ;limit=(0xbffff-0xb8000)/4k=0x7 dd DESC_VIDEO_HIGH4 ; 此时dpl已改为0 GDT的第0个段不可用，剩下三个段描述符：代码段，堆栈段，显存段；（注：段描述符 64bit = 8B(dd是4字节，所以用两个dd定义一个段描述符) 实模式下内存地址0xb8000到0xbffff是显示适配器BIOS所在区域，当段粒度是4k时，段界限大小为0xbffff-0xb800/4k = 7, 所以段界限设为7，就足够表示显示的整个内存区域了 构造段寄存器内容即选择子（16位，可以索引到段描述符，13位索引+1位TI+2位RPL） SELECTOR_CODE equ (0x0001 三个选择子的内容分别是（注意索引0是没有用的，这里三个索引1,2,3），都访问GDT而非LDT, 请求特权级都是0级 0000000000000 00 0 1 TI_GDT RPL0 2 TI_GDT RPL0 3 TI_GDT RPL0 实模式到保护模式的设置和跳转 进入保护模式，需要设置控制寄存器的cr0寄存器，其pe位置1，8686要打开A20，这些都在实模式完成，实模式也会设置GDT lgdt [gdt_ptr] GDT由gdtr寄存器加载(gdtr共48bit=6B,前16bit界限，后32bit是起始地址) GDT_SIZE equ $ - GDT_BASE GDT_LIMIT equ GDT_SIZE - 1 times 60 dq 0 ; 此处预留60个描述符的slot SELECTOR_CODE equ (0x0001 保护模式代码执行 p_mode_start: mov ax, SELECTOR_DATA mov ds, ax mov es, ax mov ss, ax mov esp,LOADER_STACK_TOP mov ax, SELECTOR_VIDEO mov gs, ax mov byte [gs:160], 'P' jmp $ 首先选择子加载到各个段寄存器，其中0xb8000-0xbfff这个是显示适配器BIOS所在区域，将SELECTOR_VIDEO段加载到了gs,也即0xb8000-0xbfff这块内存加载到gs，那么操作gs写入数据，文本就能正常显示到屏幕了 按照上一节操作运行后得到的截图， 实模式和保护模式都能显示文本 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-29 17:54:24 "},"content/04_page/":{"url":"content/04_page/","title":"4 分页","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 段、页式 分段的缺陷 分页 分页机制本质和内存映射 分页问题与解决，地址如何映射 页大小 一级分页，二级分页(页目录，页表) 段页式的地址映射 问：段页式内存访问一般需要几次内存访问 本次分页相关的代码实现 程序实现 段、页式 分段的缺陷 内存分段机制下的地址访问 原先的程序是直接访问物理地址的，采用虚拟地址和分段机制下： 解决问题1：进程地址空间不能隔离 每个程序有自己的虚拟地址，虚拟地址是可以相同的，但是会映射到不同物理地址中。确保了每个程序有独立的虚拟地址空间 解决问题2：程序地址重定位的问题 原来直接访问物理地址的情况下，程序每次需要运行时，都需要在内存中分配一块足够大的空闲区域，而问题是这个空闲的位置是不能确定的（空闲的物理内存块不是确定的），这会带来一些重定位的问题，重定位的问题确定就是程序中引用的变量和函数的地址。 分段后每个程序由自己独立的虚拟地址空间(虚拟地址会映射到相应的可分配的物理内存)，程序无需关心物理内存，只需要根据虚拟地址空间来放置变量，代码，不需要重新定位。 但是分段机制仍有不足 内存映射仍然是以程序为单位，当内存不足是时仍然需要将整个程序交换到磁盘，内存的使用效率依然很低。 即当某个进程需要一块比较大的内存空间是，若物理地址没有连续的这么一块（即便其有很多块较小的，加起来也很大），在分段机制下，该进程是无法运行的。 分页 分页机制本质和内存映射 当某个进程需要一块比较大的内存空间是，若物理地址没有连续的这么一块（即便其有很多块较小的，加起来也很大），在分段机制下，该进程仍然无法运行。而分页机制，把物理内存映射到不同页中，分页机制提供虚拟的连续内存空间给那个进程，物理上可以达到不连续的效果。 分页机制本质：将大小不同的大内存段拆分成大小相等的小内存块，可以提供虚拟的连续内存空间，映射到可以不连续到物理内存，让进程能够运行在不连续到物理空间 注意分段是基础，段页式的内存地址映射如图 分页问题与解决，地址如何映射 页大小 若一页1字节，那么4G内存空间要有4G个页，一个页要表示32位地址需要4B,页表存放在内存中，那么存放页表需要4G*4B =16GB大小，显然不合理 4G内存=内存块数量内存块大小（页数量页的大小），页大小一般是：4KB，那么需要页数量: 4GB / 4KB = 1M（即1,048,576个页），页表中需要有1,048,576个页表项，这样存储页表项需要1M*4B=4MB，这是合理的 一级分页，二级分页(页目录，页表) 物理地址则有物理页与之对应，物理页的大小也是4KB；定位到物理页后，给出相应偏移，就能访问到该页中的任意的物理内存了；存储1M的页表，需要1M*4B(页表项32bit)=4M物理存储空间 采用二级存储：一级是目录表，二级是页表 页目录表个数为1K（1024个目录页表）,这1k个页目录表可以存放到任意的物理内存中，也不需要连续存放； 每个页表可以指定1k个空间的页（每个页表有1024个页表项，一页4KB）；每个页目录表项可以表示1k * 4k = 4M的内存地址，共1024个页目录表项，则可表示1024 * 4M = 4GB的内存地址 页目录的存储需要4KB物理内存，一个页表也要4kB物理内存 页目录表和页表都将存放到内存中 段页式的地址映射 线性地址，分段得到的地址，再到页表中找到对应的页表项，再到物理地址，映射过程（二级分页） 虚拟地址高10位*4，作为页目录表内的偏移地址，加上目录表的物理地址(CR3寄存器含有页目录表基地址)，就能得到页目录的物理地址。读取页目录表的内容，可以得到页表的物理地址 虚拟地址的中间10位*4，作为页表内的偏移地址，加上步骤1的页表物理地址，将得到页表项的物理地址。读取该页表项的内容，可以得到分配的物理页的地址。 虚拟地址高10位和中间10位分别是PED和PTD的索引值，所以需要乘以4。低12位不是索引值，其范围是0-0xfff,作为页内偏移。步骤2的物理地址加上此偏移，得到最终的物理地址。 注意：每个进程都将用户自己的页表，都有4G的虚拟内存空间 问：段页式内存访问一般需要几次内存访问 3次即以上 第一次是由段表地址寄存器得段表始址后访问段表，由此取出对应段的页表在内存中的地址 第二次则是访问页表得到所要访问的物理地址 第三次才能访问真正需要访问的物理单元 本次分页相关的代码实现 页目录表 31-12位 共20位，是物理地址（20位，因为物理页也是4KB） AVL:可用 G:全局位，TLB高速缓存相关 D:脏页，当cpu对一个页面写操作时，将其设为1 A:访问位，是否被CPU访问过 PCD: Page-level Cache Disable,高速缓存是否禁用 PWT:Page-level Write-Through，页级写通 US:普通用户和超级用户位 RW:读写位 P:是否存在于物理内存中 页目录表得基址存于：页目录基址寄存器PDBR（控制寄存器cr3） 一个页目录的32位含义比较丰富，这都是为分页机制，分页算法，内存访问相关而设定的，都是有意义的。 同理，页目录项可以查阅相关资料，深入阅读。 具体实现分页机制，当然分段是前提 实现好页目录表和页表 页目录表基地址写入控制寄存器cr3 控制寄存器cr0的PG为设为1，表示分页 程序实现 页目录表（1个）和页表（1024个）都存在于物理内存中（需要自行设置物理内存的存储，设计页目录表和页表） 其中页目录表存放了1024个页目录项（每个页目录项32bit=4B）, 页目录表存储需要4KB的物理内存，每个页表有1024个页表项（每个页表项32bit=4B），一个页表也是4KB 虚拟内存4G(0-3G用户进程，3-4G是操作系统) 0 到 0x c0 000 000 (3G虚拟地址)（768个页表对应） 0xc0 000 000 到 0xff fff fff（1G虚拟地址）（256个页表对应） 物理内存低1MB，刚刚可以分成256页（一页是4KB），所以可用物理内存的低1MB 隐射到虚拟地址的3-4G这1GB为操作系统的虚拟地址，也就是内核占用物理地址的低1MB。所有进程共享内核。 建立页目录，页表; 开启分页; ; 创建页目录及页表并初始化页内存位图 call setup_page ;要将描述符表地址及偏移量写入内存gdt_ptr,一会用新地址重新加载 sgdt [gdt_ptr] ; 存储到原来gdt所有的位置 ;将gdt描述符中视频段描述符中的段基址+0xc0000000 mov ebx, [gdt_ptr + 2] or dword [ebx + 0x18 + 4], 0xc0000000 ;视频段是第3个段描述符,每个描述符是8字节,故0x18。 ;段描述符的高4字节的最高位是段基址的31~24位 ;将gdt的基址加上0xc0000000使其成为内核所在的高地址 add dword [gdt_ptr + 2], 0xc0000000 add esp, 0xc0000000 ; 将栈指针同样映射到内核地址 ; 把页目录地址赋给cr3 mov eax, PAGE_DIR_TABLE_POS mov cr3, eax ; 打开cr0的pg位(第31位) mov eax, cr0 or eax, 0x80000000 mov cr0, eax ;在开启分页后,用gdt新的地址重新加载 lgdt [gdt_ptr] ; 重新加载 mov byte [gs:160], 'V' ;视频段段基址已经被更新,用字符v表示virtual addr jmp $ Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-12-22 12:52:51 "},"content/04_page/vm.html":{"url":"content/04_page/vm.html","title":"虚拟内存","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 虚拟内存 没有虚拟内存面临的问题 1. 没有足够内存 2. 内存空洞(内存碎片问题) 3. 进程隔离和安全问题 虚拟内存如何解决上面的问题 解决问题1 解决问题2 解决问题3 Page Fault page fault类型 导致Page Fault的一些场景 页面置换算法 颠簸或抖动(thrashing) 虚拟内存 参考学习：《computer architecture》课程 没有虚拟内存面临的问题 1. 没有足够内存 程序是可以访问到32bit的4G内存的任意位置的，但是如果物理内存没有4GB，比如只有1GB（事实上，即便有4GB内存，由于内核会占用一定内存，所以留给用户的内存也没有4GB，可能只有2GB可以给用户进程用）；所以这就导致访问超过1GB内存的时候，直接Crash了 2. 内存空洞(内存碎片问题) 进程是需要连续的内存空间的，即便整体可用内存足够，但是由于是都是空洞，不连续，这样也没法让进程跑起来 3. 进程隔离和安全问题 不同的进程会访问同一个内存地址，这回导致进程相互影响，直接crash；显然进程如果没能隔离，可靠性和安全性基本无法保证 虚拟内存如何解决上面的问题 解决问题1 illusion: n.错误的观念; 幻想; 幻想的事物; 错觉; 利用磁盘交换，内存不断的交换使用,给进程造成无限内存的错觉 解决问题2 虚拟内存是映射到物理内存的，所以利用map可以映射到任意的物理内存，内存空洞/碎片问题将不再成为问题 解决问题3 虚拟内存map映射可以完美的解决程序的隔离性问题，如果映射到相同物理地址，则可以任务是进程共享的内容，否则可以映射到不同的物理内存，确保某个进程不会影响其它进程的数据 Page Fault VA：Virtual Address 虚拟地址 PA：Physical Address 物理地址 MMU：Memory Manage Unit 内存管理单元 TLB：Translation Lookaside Buffer 旁路快表缓存/地址变换高速缓存 PTE：Page Table Entry 分页表项 CPU MMU VA到PA的转换流程 当CPU给MMU传新虚拟地址之后，MMU先去问TLB那边有没有，如果有就直接拿到物理地址发到总线给内存，开始工作 TLB容量比较小，难免发生Cache Miss，这时候MMU还有保底的老武器页表 Page Table，在页表中找到之后MMU除了把地址发到总线传给内存，还把这条映射关系给到TLB，让它记录一下刷新缓存 TLB容量不满的时候就直接把新记录存储了，当满了的时候就开启了淘汰大法把旧记录清除掉，来保存新记录 如果CPU给MMU的虚拟地址在TLB和Page Table都没有找到对应的物理页帧或者权限不对，该怎么办呢？即有：page fault Page Fault：假如目标内存页在物理内存中没有对应的页帧或者存在但无对应权限，CPU 就无法获取数据，这种情况下CPU就会报告一个缺页错误；这是一个由硬件中断触发的可以由软件逻辑纠正的错误 page fault类型 Hard Page Fault 也被称为Major Page Fault，翻译为硬缺页错误/主要缺页错误，这时物理内存中没有对应的页帧，需要CPU打开磁盘设备读取到物理内存中，再让MMU建立VA和PA的映射。 Soft Page Fault 也被称为Minor Page Fault，翻译为软缺页错误/次要缺页错误，这时物理内存中是存在对应页帧的，只不过可能是其它进程调入的，发出缺页异常的进程不知道而已，此时MMU只需要建立映射即可，无需从磁盘读取写入内存，一般出现在多进程共享内存区域。 Invalid Page Fault 翻译为无效缺页错误，比如进程访问的内存地址越界访问，又比如对空指针解引用内核就会报segment fault错误中断进程直接挂掉。 导致Page Fault的一些场景 非法操作访问越界 这种情况产生的影响也是最大的，也是Coredump的重要来源，比如空指针解引用或者权限问题等都会出现缺页错误。 使用malloc新申请内存 malloc机制是延时分配内存，当使用malloc申请内存时并未真实分配物理内存，等到真正开始使用malloc申请的物理内存时发现没有才会启动申请，期间就会出现Page Fault。 访问数据被swap换出 物理内存是有限资源，当运行很多进程时并不是每个进程都活跃，对此OS会启动内存页面置换将长时间未使用的物理内存页帧放到swap分区来腾空资源给其他进程，当存在于swap分区的页面被访问时就会触发Page Fault从而再置换回物理内存。 页面置换算法 当主存空间已满而又需要装入新页时（或者有缺页中断发生时），页式虚拟存储管理必须按照一定的算法把已在主存的一些页调出去。选择淘汰页的工作称为页面调度，选择淘汰页的算法称为页面调度算法，页面调度算法设计不当，会出现刚被淘汰的页面立即又要调入，并如此反复，这种现象称为抖动或颠簸。 最佳页面替换算法（OPT）：理想的调度算法，只可模拟，不可实现。当要调入新页面时，首先淘汰以后不再访问的页，然后选择距现在最长时间后再访问的页。 先进先出页面调度算法（FIFO）：总是淘汰最先调入主存的那一页，或者说主存驻留时间最长的那一页(常驻的除外)。模拟的是程序执行的顺序性，有一定合理性。会出现Belady现象（如果对—个进程未分配它所要求的全部页面，有时就会出现分配的页面数增多但缺页率反而提高） 最近最少用页面调度算法（LRU）：淘汰最近一段时间内最久未被访问的那一页，认为那些刚被使用过的页面可能还要立即被使用，而那些在较长时间内未被使用的页面可能不会立即使用。模拟了程序执行的局部属性，既考虑了循环性又兼顾了顺序性，但严格实现的代价大（需要维持特殊队列），模拟实现的方法为： 1.最近未使用页面替换算法（NRU）/引用位法：每页建一个引用位，供硬件使用；设置一个时间间隔中断，周期性地把所有页的引用位置0；地址转换时，页引用标志置1；淘汰页面时，从页引用标志为0的页中间随机选择。该方法开销小但时间间隔多长是个难点。 最不经常使用页面替换算法（NFU）/计数法：基于时间间隔中断，并给每一页设置一个页引用计数器；时间间隔中断发生后，所有计数器置0；每访问页1次就给计数器加1；淘汰页面时，选择计数值最小的页面淘汰。 计时法：基于时间间隔中断，为每页增设一个计时单元；每当页面被引用时把当前绝对时间置入计时单元；时间间隔中断发生后，所有计时单元全部清除；淘汰页面时，选择绝对时间最小的页面淘汰。 老化算法：基于时间间隔中断，为每个页设置一个多位寄存器；每当页面被访问时，寄存器最左边位置0；时间间隔中断发生后，所有寄存器右移一位；淘汰页面时，选择值最小的寄存器对应的页面淘汰。 LFU(Least Frequently Used) 第二次机会页面调度算法（SCR）：淘汰最先进入内存的页面如果最近还在使用，仍然有机会像新调入页面一样留在内存中。页面调入主存时，其引用标志位置1；访问主存页面时，其引用标志位置1；淘汰页面时，从FIFO页面队列对首开始扫描，把所遇到的引用标志位是1的页面的引用标志位清0，并移至队尾（看作新调入的页再给一次机会），把所遇到的引用标志位是0的页面淘汰（其最早进入内存且最久未被使用）。 时钟页面替换算法（Clock）：采用循环队列机制构造页面队列，形成了一个类似于钟表面的环形表。队列指针则相当于钟表面上的表针，指向可能要淘汰的页面。使用页引用标志位。页面调入主存时，其引用标志位置1；访问主存页面时，其引用标志位置1；淘汰页面时，从指针当前指向的页面开始扫描循环队列，把所遇到的引用标志位是1的页面的引用标志位清0，并跳过，把所遇到的引用标志位是0的页面淘汰，指针推进一步。 颠簸或抖动(thrashing) thrash：v.(作为惩罚用棍子等) 抽打，连续击打; (使) 激烈扭动，翻来覆去; 彻底击败，重创(对手); n.快节奏重金属摇滚乐; 载歌载舞的聚会; 在更换页面时，如果更换页面是一个很快会被再次访问的页面，则再次缺页中断后又很快会发生新的缺页中断。整个系统的效率急剧下降，这种现象称为颠簸（抖动）；颠簸本质上是指频繁的页调度行为 内存颠簸的解决策略： 如果是因为页面替换策略失误，可以修改替换算法来解决这个问题； 如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要降低多道程序的数量。 否则，还剩下两个办法：1.终止该进程；2.增加物理内存容量； Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-12-22 12:57:52 "},"content/04_page/os.html":{"url":"content/04_page/os.html","title":"再谈操作系统","keywords":"","body":"操作系统是什么 控制计算机的各种硬件资源：硬盘，网卡，cpu 系统调用、异常处理、文件系统 内存管理：虚拟内存，进程调度 。。。 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-12-22 12:58:08 "},"content/05_efi/":{"url":"content/05_efi/","title":"5 ELF文件理解","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 EFI文件 通过.c文件得到ELF文件 ELF文件分析 elf文件总结 内核如何运行起来，相关概念和流程 加载内核 初始化内核 内核映像，真正的内核 附：ELF文件的常见段 附：linux下查看elf文件相关信息 EFI文件 需要理解c语言，汇编语言，指令，虚拟地址这些概念，进一步了解ELF文件格式 通过.c文件得到ELF文件 main.c int main(void) { while(1); return 0; } 生成目标文件 $gcc -c -o main.o main.c $john@ubuntu:~/c_cpp$ file main.o main.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped 查看目标文件的符号 john@ubuntu:~/c_cpp$ nm main.o 0000000000000000 T main 指定目标文件的起始虚拟地址 $ld main.o -Ttext 0xc0001500 -e main -o kernel.bin -Ttext 指定可执行文件的起始虚拟地址 -e 指定可执行文件的起始地址（可以数字或符号） 不加-e会出现找不到入口符号(entry symbol)错误，如下所示 _start是默认的入口符号，所以将main.c改成如下的,则没有问题 //int main(void) int _start(void) { while(1); return 0; } kernel.bin就是一个可执行的文件 john@ubuntu:~/c_cpp$ file kernel.bin kernel.bin: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped 手动编译的test.bin和ld链接的kernel.bin 小结： C语言编译出来的汇编语言，一般比直接汇编生成的体积要大，不过都是转成汇编再到机器指令，让cpu执行。C语言编译出来的汇编，加上了编译器的很多东西，但汇编后，仍然是我们熟悉的汇编格式的，所以用C语言写内核没有任何问题。 任何程序都要加载到内核才能运行，可以发现程序要有入口地址，这样就能被调用了；操作系统调用用户程序就是这样的，有了入口地址，简单的jmp 或者 call 指令就能去执行程序了。 ELF文件分析 把程序分成 程序头 和 程序体 程序头描述程序的元信息 程序体存储代码，数据等 拿到一个程序头，去解析它，就能得到该程序的所有信息了，执行它就行。可以当成一种格式，一种协议，约定好就行了。这样程序的加载地址随意，给我头部信息就行了。 原来我们写操作系统，mbr,loader的地址都是固定的，这其实可以不那么固定. header.S header: program_length dd program_end-program_start start_addr dd program_start ;;; body: program_start: mov ax, 0x1234 jmp $ program_end: nasm -o header.bin header.S john@ubuntu:~/c_cpp$ xxd header.bin 0000000: 0500 0000 0800 0000 b834 12eb fe .........4... john@ubuntu:~/c_cpp$ 程序长度： 0x00 00 00 05 程序的起始地址：0x00 00 00 08 b834 12eb fe b8 3412 ==> mov eax 0x1234 ebfe ==> jmp $ 文件格式===>elf也是一种格式，只是比起我们自定的格式要复杂而已；ELF格式的二进制文件 实例分析 john@ubuntu:~/c_cpp$ ls header.bin header.S kernel.bin main.c main.o Makefile test.bin john@ubuntu:~/c_cpp$ file kernel.bin kernel.bin: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped john@ubuntu:~/c_cpp$ elf头部信息 #define EI_NIDENT 16 typedef struct elf32_hdr{ unsigned char e_ident[EI_NIDENT]; Elf32_Half e_type; Elf32_Half e_machine; Elf32_Word e_version; Elf32_Addr e_entry; /* Entry point */ Elf32_Off e_phoff; Elf32_Off e_shoff; Elf32_Word e_flags; Elf32_Half e_ehsize; Elf32_Half e_phentsize; Elf32_Half e_phnum; Elf32_Half e_shentsize; Elf32_Half e_shnum; Elf32_Half e_shstrndx; } Elf32_Ehdr; typedef struct elf64_hdr { unsigned char e_ident[EI_NIDENT]; /* ELF \"magic number\" */ Elf64_Half e_type; Elf64_Half e_machine; Elf64_Word e_version; Elf64_Addr e_entry; /* Entry point virtual address */ Elf64_Off e_phoff; /* Program header table file offset */ Elf64_Off e_shoff; /* Section header table file offset */ Elf64_Word e_flags; Elf64_Half e_ehsize; Elf64_Half e_phentsize; Elf64_Half e_phnum; Elf64_Half e_shentsize; Elf64_Half e_shnum; Elf64_Half e_shstrndx; } Elf64_Ehdr; e_ident数组（16字节） 观察二进制 0000000: 7f45 4c46 0201 0100 0000 0000 0000 0000 .ELF............ 7f45 4c 46 表示 0x7f 'E' , 'L', 'F' 接下来02, 表示是64位的ELF文件 接下来01，表示编码格式是小端字节序（LSB） 再接着01，表示 EFI头版本，默认就是1 接下来都是0, 保留用 与通过file命令看到的是一致的。 elf文件总结 ELF文件是一种文件格式，可以被解析的 程序（想想汇编语言）就是各种段（segment）和节(section)，当然还有数据，段和节的数量是不固定的，ELF文件会给出相关信息的 程序有入口地址，各个段地址，这些都会被解析到内核中，这样一个程序能加载到内核中并运行 内核如何运行起来，相关概念和流程 首先我们把kernel.bin，写入磁盘 加载内核 把磁盘上的kernel文件加载到内存缓冲区（也就是读磁盘，加载到一块可用内存中） 初始化内核 内存中有了kernel（ELF格式的可执行文件），loader完成了分段，分页后，需要解析kernel文件，把它安置到相应的虚拟内存地址上去，这样直接跳转到此地址，然后loader结束，开始执行kernel 内核映像，真正的内核 内核被加载内存后，一份是ELF文件自身；一份将是解析后的ELF文件内的各种段内容(此才是可以执行的，此时内核映像)，内核映像就是将程序中的各种段(segment)复制到内存中的程序（有虚拟地址），这是真正的内核 附：ELF文件的常见段 .text:存放代码（如：函数）和部分整数常量（应该指的是一些立即数）。这个段是只读的 .data:用来存放初始化了的（initailized）全局变量（global）和初始化了的静态变量（static）。它是可读可写的 .bss:全局变量数据段。它用来存放未初始化的（uninitailized）全局变量（global）和未初始化的静态变量（static）。它也是可读可写的。bss是英文Block Started by Symbol的缩写。之所以把bss跟data分开来，是因为系统会为这些bss段的变量的初值清零。 .strtab : String Table 字符串表，用于存储 ELF 文件中用到的各种字符串。 .symtab : Symbol Table 符号表，从这里可以所以文件中的各个符号。 .shstrtab : 是各个段的名称表，实际上是由各个段的名字组成的一个字符串数组。 .hash : 符号哈希表。 .line : 调试时的行号表，即源代码行号与编译后指令的对应表。 .dynamic : 动态链接信息。 .debug : 调试信息。 .comment : 存放编译器版本信息，比如 \"GCC:(GNU)4.2.0\"。 .plt 和 .got : 动态链接的跳转表和全局入口表。 .init 和 .fini : 程序初始化和终结代码段。 .rodata1 : Read Only Data，只读数据段，存放字符串常量，全局 const 变量，该段和 .rodata 一样。 内核运行中的进程中各段 附：linux下查看elf文件相关信息 mubi@v1:~/fork$ size a.out text data bss dec hex filename 1296 552 8 1856 740 a.out mubi@v1:~/fork$ file a.out a.out: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=7f4cda815bd32ca6db97a76469066d6c3086600a, not stripped mubi@v1:~/fork$ Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-29 15:10:11 "},"content/06_kernel_start/":{"url":"content/06_kernel_start/","title":"6 C语言写内核","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 开始自己写内核 程序编码，虚拟机运行 操作系统说明 磁盘结构，虚拟地址 mbr loader 内核代码 文件加载，内核运行 打印函数 开始自己写内核 根据前面的基础，写一个简单的内核：打印字符然后驻留。 《操作系统真相还原》给出了源代码，我力图自己实践理解，确保有代码，也有运行截图（需要注意运行环境）。 我们需要理解磁盘上文件是如何安排的，1M的物理内存如何使用的，4G的虚拟内存如何使用的？ 程序编码，虚拟机运行 代码目录结构 注意上述文件的编译运行在32bit的linux环境下,因为要解析ELF文件，需要保持一致（32位和64位的ELF文件格式，有些数据结构大小，字段可能不同，所以解析会不同） Makefile .PHONY:build image clean img=/home/john/os/hd30M.img mbr_src=mbr.S loader_src=loader.S mbr=mbr.bin loader=loader.bin mbr_loader: nasm -I boot/include/ -o boot/${mbr} boot/${mbr_src} nasm -I boot/include/ -o boot/${loader} boot/${loader_src} build: nasm -f elf -o lib/kernel/print.o lib/kernel/print.S gcc -I lib/kernel -c -o kernel/main.o kernel/main.c ld -Ttext 0xc0001500 -e main -o kernel/kernel.bin kernel/main.o lib/kernel/print.o image: @-rm -rf $(img) bximage -hd -mode=\"flat\" -size=30 -q $(img) dd if=./boot/mbr.bin of=$(img) bs=512 count=1 conv=notrunc dd if=./boot/loader.bin of=$(img) bs=512 seek=2 count=3 conv=notrunc dd if=./kernel/kernel.bin of=$(img) bs=512 seek=9 count=200 conv=notrunc clean: @-rm -rf boot/*.img boot/*.bin boot/*.o /boot/*~ @-rm -rf lib/*.img lib/*.bin lib/*.o lib/*~ @-rm -rf lib/kernel/*.img lib/kernel/*.bin lib/kernel/*.o lib/kernel/*~ @-rm -rf kernel/*.img kernel/*.bin kernel/*.o kernel/*~ @-rm -rf *.o *.bin *.img *~ main.c（kernel） #include \"print.h\" void main(void) { put_char('k'); put_char('e'); put_char('r'); put_char('n'); put_char('e'); put_char('l'); put_char('\\n'); put_char('1'); put_char('2'); put_char('\\b'); put_char('3'); while(1); } 其中\\n表示换行,\\b表示删除前一字符,最后bochs运行结果图 操作系统说明 磁盘结构，虚拟地址 mbr 被加载到物理地址0x7c00，有BIOS读取磁盘的mbr分区（即磁盘的第一个扇区-512字节） mbr负责读取磁盘2-4扇区的loader内容，加载在物理内存 可用区域，我们选择了0x9000，mbr结束自己，跳转到loader入口地址 loader loader建立分段，分页机制等，并读取内核所在的磁盘区域，把内核加载到内存，然后跳转到内核入口处，结束自己 内核代码 内核的kernel.bin有两个地址，一个是ELF文件地址，这个被加载到物理内存可用区域的0x70000;另一个是解析ELF后的内核映像，这个加载到了0x1500(loader设计的内存大小不超过2000字节，0x9000+2000字节 = 0x1d10，然后空了些，内核选择了0x1500开始后的物理内存） 页表中设置了内核低端1MB的虚拟内存与物理内存一一对应 所以，物理地址0x1500对应到内核虚拟地址就是0xc0001500，这也就是内核入口的虚拟地址（Makefile中编译出kernel.bin就设置的这个地址） 文件加载，内核运行 内核文件目前就是main.o和print.o链接的，print使用汇编写的操作了显存，这样可以将文本输出到屏幕上，main直接调用就行了。 print涉及到光标和单字符的显示，这个是基础的显存操作，后面打印字符串，打印整数可以在此函数上基础上封装。 采用了函数调用方式（参数传递，栈变化，函数执行返回等这些需要理解） 打印函数 put_str 不断的调用put_char函数，实现打印字符串的功能 ;-------------------------------------------- ;put_str 通过put_char来打印以0字符结尾的字符串 ;-------------------------------------------- ;输入：栈中参数为打印的字符串 ;输出：无 global put_str put_str: ;由于本函数中只用到了ebx和ecx,只备份这两个寄存器 push ebx push ecx xor ecx, ecx ; 准备用ecx存储参数,清空 mov ebx, [esp + 12] ; 从栈中得到待打印的字符串地址 .goon: mov cl, [ebx] cmp cl, 0 ; 如果处理到了字符串尾,跳到结束处返回 jz .str_over push ecx ; 为put_char函数传递参数 call put_char add esp, 4 ; 回收参数所占的栈空间 inc ebx ; 使ebx指向下一个字符 jmp .goon .str_over: pop ecx pop ebx ret put_int put_int 将数字转成字符，存到一个字符串buffer中，然后put_char 当然并未输出10进制的数，而是打印每个字节内容 mian.c调用 #include \"print.h\" void main(void) { put_str(\"I am kernel\\n\"); put_int(0); put_char('\\n'); put_int(9); put_char('\\n'); put_int(0x00021a3f); put_char('\\n'); put_int(0x12345678); put_char('\\n'); put_int(0x00000000); while(1); } 结果图 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-29 14:58:51 "},"content/07_interrupt/":{"url":"content/07_interrupt/","title":"7 中断基础","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 中断 采用中断系统的主要目的 中断分类 内部中断 外部中断 CPU处理外部中断 中断描述符表 利用Intel 8259A芯片实现一个中断处理程序 时钟 中断 中断概念，作用，中断描述符表等相关概念理解。 编写中断处理程序 采用中断系统的主要目的 来自百度百科 提高计算机系统效率。计算机系统中处理机的工作速度远高于外围设备的工作速度。通过中断可以协调它们之间的工作。当外围设备需要与处理机交换信息时，由外围设备向处理机发出中断请求，处理机及时响应并作相应处理。不交换信息时，处理机和外围设备处于各自独立的并行工作状态。 维持系统可靠正常工作。现代计算机中，程序员不能直接干预和操纵机器，必须通过中断系统向操作系统发出请求，由操作系统来实现人为干预。主存储器中往往有多道程序和各自的存储空间。在程序运行过程中，如出现越界访问，有可能引起程序混乱或相互破坏信息。为避免这类事件的发生，由存储管理部件进行监测，一旦发生越界访问，向处理机发出中断请求，处理机立即采取保护措施。 满足实时处理要求。在实时系统中，各种监测和控制装置随机地向处理机发出中断请求，处理机随时响应并进行处理。 提供故障现场处理手段。处理机中设有各种故障检测和错误诊断的部件，一旦发现故障或错误，立即发出中断请求，进行故障现场记录和隔离，为进一步处理提供必要的依据。 中断分类 cpu工作是串行的，所有任务，包括中断处理都是一个接着一个在cpu中运行的，共享CPU,CPU在各个任务不断切换实现并发。 \"操作系统是中断驱动的\"，按中断源分为：内部中断和外部中断 内部中断 来自CPU内部，如内存读写错误，程序运行错误；按是否正常可分为软中断和异常 软中断 由软件主动发起的中断，不是客观的内部错误 异常 是在指令执行过程中由于微处理器内部操作发生异常引起的，如硬件失效或非法的系统调用，以及程序员预先设置断点等。 异常按轻重程度分为 Fault(故障)，如 page fault(分页异常)，这种异常最轻，可以被恢复 Trap(陷阱) Abort(终止) cpu保护自己，直接终止程序的运行。导致此异常通常是硬件错误，或者某些系统数据结构错误 外部中断 由外部设备：网卡，硬盘，打印机等发出的中断 CPU通过指令限制某些设备发出中断请求，称为屏蔽中断。从CPU要不要接收中断即能不能限制某些中断发生的角度 ，中断可分为 可屏蔽中断 可被CPU通过指令限制某些设备发出中断请求的中断 不可屏蔽中断(non-maskable interrupt，NMI) 不允许屏蔽的中断如电源掉电。 主要用于处理系统的意外或故障，如电源掉电、存储器读/写错误、扩展槽中输入/输出通道错误等。 CPU处理外部中断 为了让 CPU 获得每个外部设备的中断信号，最好的方式是在 CPU 中为每一个外设准备一个引脚接收中断，但这是不可能的，计算机中挂了很多外部设备，而且理论上外设数量是没有上限的，无论CPU中准备多少引脚都不够用，况且，我们还嫌CPU的体积太大呢，再整点引脚上去， CPU 岂不是更大了 。 CPU提供两条引线，如下图（INTR和NMI两条） 所有外部中断都走这其中的一条引线，INTR处理可屏蔽的中断，CPU可以随时处理，也可以不处理，他并不影响CPU的运行；NMI处理不可屏蔽的中断，这些中断全是硬伤，cpu都没有必要运行下去了，直接回宕机。 中断描述符表 类似段表，页表，保护模式下中断处理程序采用中断描述符表，中断描述符表存放中断处理程序的入口，其中中断描述符也称为门（又可分为陷阱门，调用门，任务门等等） 实模式下存储中断处理程序的入口地址的表叫做中断向量表（Interrupt Vetor Table, LVT） 内核初始化时，初始化可编程控制器8259A；将中断向量IDT 表的起始地址装入IDTR 寄存器，并初始化表中的每一项。 用户进程可以通过INT指令发出一个中断请求，其中断请求向量在0～255 之间。为了防止用户使用INT 指令模拟非法的中断和异常，必须对IDT 表进行谨慎的初始化。其措施之一就是将中断门或陷阱门中的DPL 域置为0。如果用户进程确实发出了这样一个中断请求，CPU 会检查出其CPL（3）与DPL（0）有冲突，因此产生一个“通用保护”异常。 但是，有时候必须让用户进程能够使用内核所提供的功能（比如系统调用），也就是说从用户空间进入内核空间，这可以通过把中断门或陷阱门的DPL 域置为3 来达到。 利用Intel 8259A芯片实现一个中断处理程序 可编程中断控制器8259A 的作用是负责所有来自外设的中断，其中就包括来自时钟的中断，可以通过它完成进程调度。 8259A的信号和寄存器 INT: 8259A 选出优先级最高的中断请求后，发信号通知 CPU。 INTA: INT Acknowledge，中断响应信号 。 位于 8259A 中的 INTA 接收来自 CPU 的剧τA 接口的中断响应信号。 IMR: Interrupt Mask Register，中断屏蔽寄存器，宽度是 8 位，用来屏蔽某个外设的中断 。 IRR: Interrupt Request Register，中断请求寄存器，宽度是 8 位。它的作用是接受经过 IMR 寄存器过滤后的中断信号并锁存，此寄存器中全是等待处理的中断，“相当于” 5259A 维护的未处理中断信号队列 。 PR: Priority Resolver，优先级仲裁器 。 当有多个中断同时发生，或当有新的中断请求进来时，将它与当前正在处理的中断进行比较，找出优先级更高的中断。 ISR: In-Servi臼 Register，中断服务寄存器，宽度是 8 位。当某个中断正在被处理时，保存在此寄存器中 。 中断处理框架 构造好IDT(Interrupt Descriptor Table) 中断描述符表（ Interrupt Descriptor Table, IDT），是保护模式下用于存储中断处理程序入口的表，当CPU 接收一个中断时，需要中断向量在此表中检索对应的描述符，在该描述符中找到中断处理程序的起始地址，然后执行中断处理程序。 提供中断向量号 外部设备不知道中断向量号这回事，它只负责发中断信号，中断向量号是 8259A 传送给 CPU 的 自己为外部设备设置好，中断向量号，然后自己在中断描述符表中的对应项添加好合适的中断处理程序。 中断处理流程图 时钟 在计算机系统中也一样，为了使所有设备之间的通信井然有序，各通信设备间必须有统一的节奏，不能各干各的，这个节奏就称为定时或时钟 时钟只是一种时间的度量，只是一种节奏，其时间长度并不统一，各种设备都有自己的时钟，也就是说都有自己的工作节拍，比如处理器的时钟和外部设备的时钟肯定不是一个数量级，让处理器这种高速设备以外部设备低速时钟工作，处理器肯定会觉得很闲。而让低速的外部设备以处理器的时钟节拍工作，外部设备也许会急得不知所措，完全跟不上节奏。 计算机中的时钟，大致上可分为两大类：内部时钟和外部时钟。 内部时钟 内部时钟是指处理器中内部元件，如运算器、控制器的工作时序，主要用于控制、同步内部工作过程的步调。内部时钟是由晶体振荡器产生的，简称晶振，它位于主板上，其频率经过分频之后就是主板的外频，处理器和南北桥之间的通信就基于外频。Intel 处理器将此外频乘以某个倍数（也称为倍频）之后便称为主频。处理器取指令、执行指令中所消耗的时钟周期，都是基于主频的。内部时钟是由处理器固件结构决定的，在出厂时就设定好啦，无法改变。处理器内部元件的工作速度是最快的，所以内部时钟的时间单位粒度比较精细，通常都是纳秒（ns）级的。 外部时钟 外部时钟是指处理器与外部设备或外部设备之间通信时采用的一种时序，比如 IO 接口和处理器之间在 AID 转换时的工作时序、两个串口设备之间进行数据传输时也要事先同步时钟等。外部设备的速度对于处理器来说就很慢了，所以其时钟的时间单位粒度较大 一般是毫秒(ms)级或秒 (s)级的。 当外部设备与处理器连接，组成了 一个计算机系统后，我们就要考虑处理器与外部设备间同步数据时的时序配合问题，如何保证运行在不同时钟节拍下的设备能够同步通信？ 硬件定时器 钟表和计数器其实属于同一类物品，时间本质上就是个没有设定目标终止值的计数器，这个计数器每时每刻都在不停地计数，通常这个计数的单位是秒 。所以，时间就是计数，计数也称为定时，它们本质上是一回事。 硬件定时器一般有两种计时的方式 正计时：每一次时钟脉冲发生时，将当前计数值加 l ，直到与设定的目标终止值相等时，提示时间已到，典型的例子就是闹钟。 倒计时：先设定好计数器的值，每一次时钟脉冲发生时将计数值减 1 ，直到为 0 时提示时间已到，典型的例子就是电风扇的定时。 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-09-08 08:52:25 "},"content/07_interrupt/system_call.html":{"url":"content/07_interrupt/system_call.html","title":"系统调用","keywords":"","body":"系统调用 操作系统对用户进程提供服务的接口 通过软中断触发中断 INT和IRET指令用于系统调用，系统调用时，有堆栈切换和特权级的切换 系统调用简单流程 当应用程序调用系统调用时，软中断触发0x80中断（要保护现场：如用户进程的值都保存到寄存器） CPU收到中断信号，从中断向量表中，拿到中断服务例程，得到中断号 通过中断号，从系统调用表中找到系统调用程序（用户无法访问的，内核的某个地址），然后开始执行（内核态就可以随心所欲操作了） 执行完之后，再恢复现场，返回上层应用程序，用户进程接着运行 对系统调用的认识，至少要认识到如下两点： 系统调用涉及到用户态和内核态切换，是通过中断实现的 系统调用的成本比用户态的函数调用的成本高 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-09-07 23:45:57 "},"content/08_assert/":{"url":"content/08_assert/","title":"8 内核Assert函数","keywords":"","body":"断言函数assert 一种是为内核系统使用的ASSERT，另一种是为用户进程使用的assert 一方面，当内核运行中出现问题时，多属于严重的错误，着实没必要再运行下去了。另一方面，断言在输出报错信息时，屏幕输出不应该被其它进程干扰，这样咱们才能专注于报错信息。综上两点原因，ASSERT 排查出错误后，最好在关中断的情况下打印报错信息 。 ASSERT 是用来辅助程序调试的，所以通常是用在开发阶段。如果程序中的某些地方会莫名其妙地出错，而我们又无法短时间内将其排查出来，这时我们可以在程序中安排个“哨兵”，这个哨兵就是 ASSERT。我们把程序该有的条件状态传给它，让它帮咱们监督此条件，一旦条件不符合就会报错井将程序挂起。 ASSERT （条件表达式｝ ； debug.h，定义ASSERT函数 #ifndef __KERNEL_DEBUG_H #define __KERNEL_DEBUG_H void panic_spin(char* filename, int line, const char* func, const char* condition); /*************************** __VA_ARGS__ ******************************* * __VA_ARGS__ 是预处理器所支持的专用标识符。 * 代表所有与省略号相对应的参数. * \"...\"表示定义的宏其参数可变.*/ #define PANIC(...) panic_spin (__FILE__, __LINE__, __func__, __VA_ARGS__) /***********************************************************************/ #ifdef NDEBUG #define ASSERT(CONDITION) ((void)0) #else #define ASSERT(CONDITION) \\ if (CONDITION) {} else { \\ /* 符号#让编译器将宏的参数转化为字符串字面量 */ \\ PANIC(#CONDITION); \\ } #endif /*__NDEBUG */ #endif /*__KERNEL_DEBUG_H*/ debug.c #include \"debug.h\" #include \"print.h\" #include \"interrupt.h\" /* 打印文件名,行号,函数名,条件并使程序悬停 */ void panic_spin(char* filename, \\ int line, \\ const char* func, \\ const char* condition) \\ { intr_disable(); // 因为有时候会单独调用panic_spin,所以在此处关中断。 put_str(\"\\n\\n\\n!!!!! error !!!!!\\n\"); put_str(\"filename:\");put_str(filename);put_str(\"\\n\"); put_str(\"line:0x\");put_int(line);put_str(\"\\n\"); put_str(\"function:\");put_str((char*)func);put_str(\"\\n\"); put_str(\"condition:\");put_str((char*)condition);put_str(\"\\n\"); while(1); } main.c #include \"print.h\" #include \"init.h\" #include \"debug.h\" int main(void) { put_str(\"I am kernel\\n\"); init_all(); ASSERT(1==2); while(1); return 0; } 运行截图 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-09-05 18:50:05 "},"content/09_memory_management/":{"url":"content/09_memory_management/","title":"9 内存管理、内存池、地址映射","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 内存管理 使用位图管理内存 位图中申请内存 内存池 内存分布 回顾虚拟地址到物理地址的转换 运行截图 内存管理 使用位图管理内存 1位 对应 一个内存页 1位 有两个状态，0 或 1，可以表示有 和 无，如1表示的资源被占用，0表示资源可用 bimap.h #ifndef __LIB_KERNEL_BITMAP_H #define __LIB_KERNEL_BITMAP_H #include \"global.h\" #define BITMAP_MASK 1 struct bitmap { uint32_t btmp_bytes_len; /* 在遍历位图时,整体上以字节为单位,细节上是以位为单位,所以此处位图的指针必须是单字节 */ uint8_t* bits; }; void bitmap_init(struct bitmap* btmp); bool bitmap_scan_test(struct bitmap* btmp, uint32_t bit_idx); int bitmap_scan(struct bitmap* btmp, uint32_t cnt); void bitmap_set(struct bitmap* btmp, uint32_t bit_idx, int8_t value); #endif bitmap结构体 struct bitmap { uint32_t btmp_bytes_len; /* 在遍历位图时,整体上以字节为单位,细节上是以位为单位,所以此处位图的指针必须是单字节 */ uint8_t* bits; }; 一个字节有8位，每一位都对应一个物理页；bitmap结构体类似一个单链表节点， 每一个位有一个长度，每一个bitmap的地址有上一个链地址给出。 位图中申请内存 一个字节的内容只要不是0xff就表示该字节里面还有空位, 空位连续代表内存地址连续，即能分配连续内存空间 先逐个字节判断 所有字节都找不到，就失败 某个字节若有空位 在字节里面，逐个位判断，再到空位 取的空位的下标 idx_byte * 8 表示某个字节 再 + idx 得到真正的位 判断连续的空位是否满足 cnt 个 /* 在位图中申请连续cnt个位,成功则返回其起始位下标，失败返回-1 */ int bitmap_scan(struct bitmap* btmp, uint32_t cnt) { uint32_t idx_byte = 0; // 用于记录空闲位所在的字节 /* 先逐字节比较,蛮力法 */ while (( 0xff == btmp->bits[idx_byte]) && (idx_byte btmp_bytes_len)) { /* 1表示该位已分配,所以若为0xff,则表示该字节内已无空闲位,向下一字节继续找 */ idx_byte++; } ASSERT(idx_byte btmp_bytes_len); if (idx_byte == btmp->btmp_bytes_len) { // 若该内存池找不到可用空间 return -1; } /* 若在位图数组范围内的某字节内找到了空闲位， * 在该字节内逐位比对,返回空闲位的索引。*/ int idx_bit = 0; /* 和btmp->bits[idx_byte]这个字节逐位对比 */ while ((uint8_t)(BITMAP_MASK bits[idx_byte]) { idx_bit++; } int bit_idx_start = idx_byte * 8 + idx_bit; // 空闲位在位图内的下标 if (cnt == 1) { return bit_idx_start; } uint32_t bit_left = (btmp->btmp_bytes_len * 8 - bit_idx_start); // 记录还有多少位可以判断 uint32_t next_bit = bit_idx_start + 1; uint32_t count = 1; // 用于记录找到的空闲位的个数 bit_idx_start = -1; // 先将其置为-1,若找不到连续的位就直接返回 while (bit_left-- > 0) { if (!(bitmap_scan_test(btmp, next_bit))) { // 若next_bit为0 count++; } else { count = 0; } if (count == cnt) { // 若找到连续的cnt个空位 bit_idx_start = next_bit - cnt + 1; break; } next_bit++; } return bit_idx_start; } 内存池 内存池： 把可用内存集中到一个池子中，需要就从中取/不需要就可以放回去。 内核和用户进程最终都是运行在物理内存中的，所以需要规划好物理内存，哪些是运行内核的，哪些运行用户进程的？ 这里把物理内存分为两个内存池，一个给用户进程，一个给内核进程； 操作系统必须确保自己有足够的内存运行，否则物理内存不足，机器要挂。 内存池按单位分配内存，一块大小为4KB，也就是每次取 4KB, 8KB，12KB这种以4KB为单位的一块或多块，当然块单位的粒度可以调整。 虚拟地址大小4G，每个进程都拥有4G的虚拟地址空间，所以每个进程都维持一个虚拟地址池。 每个程序的虚拟地址是在链接时分配好了的，需要找空闲的物理内存，映射好，然后程序才能执行 memory.h #ifndef __KERNEL_MEMORY_H #define __KERNEL_MEMORY_H #include \"stdint.h\" #include \"bitmap.h\" /* 用于虚拟地址管理 */ struct virtual_addr { struct bitmap vaddr_bitmap; // 虚拟地址用到的位图结构 uint32_t vaddr_start; // 虚拟地址起始地址 }; extern struct pool kernel_pool, user_pool; void mem_init(void); #endif 以页为单位管理虚拟地址的分配情况；虚拟地址也要分配。虽然多个进程可以拥有相同的虚拟地址，但究其原因，是因为这些虚拟地址所对应的物理地址是不同的。但是，在同一个进程内的虚拟地址必然是唯一的，这通常是由链接器为其分配的；进程在运行时可以动态从堆中申请内存，系统为其分配的虚拟地址也属于此进程的虚拟地址空间，也必须要保证虚拟地址的唯一性，所以，用位图来记录虚拟地址的分配情况。 采用位图管理内存，1位对应一页大小4KB；对于bochs设置的32MB的物理内存 ，需要32M / 4K = 8K bit = 1K字节，也即位图存储需要1/4页,即1/4页就可以表示32M的物理内存了，本例采用4页来管理物理内存，那么最大可以管理512MB的物理内存。 内存分布 我们的操作系统具体的内存情况如下图 物理内存低1M用来存储必要的信息：MBR,loader,GDT,位图，内核栈等等信息 分页所需的页目录表，页表等接着存储到物理内存中 剩下的物理内存才是真正可用的，这些内存要给内核和用户进程用 主要我们的内存都是整页的，所有可能会浪费一些物理内存，内存池取内存也是整页整页的分配的。 看看数据结构 /* 内存池标记,用于判断用哪个内存池 */ enum pool_flags { PF_KERNEL = 1, // 内核内存池 PF_USER = 2 // 用户内存池 }; /* 用于虚拟地址管理 */ struct virtual_addr { /* 虚拟地址用到的位图结构，用于记录哪些虚拟地址被占用了。以页为单位。*/ struct bitmap vaddr_bitmap; /* 管理的虚拟地址 */ uint32_t vaddr_start; }; /* 内存池结构,生成两个实例用于管理内核内存池和用户内存池 */ struct pool { struct bitmap pool_bitmap; // 本内存池用到的位图结构,用于管理物理内存 uint32_t phy_addr_start; // 本内存池所管理物理内存的起始地址 uint32_t pool_size; // 本内存池字节容量 }; struct pool kernel_pool, user_pool; // 生成内核内存池和用户内存池 struct virtual_addr kernel_vaddr; // 此结构是用来给内核分配虚拟地址 功能函数 /* 在pf表示的虚拟内存池中申请pg_cnt个虚拟页, * 成功则返回虚拟页的起始地址, 失败则返回NULL */ static void* vaddr_get(enum pool_flags pf, uint32_t pg_cnt) /* 得到虚拟地址vaddr对应的pte指针*/ uint32_t* pte_ptr(uint32_t vaddr) /* 在m_pool指向的物理内存池中分配1个物理页, * 成功则返回页框的物理地址,失败则返回NULL */ static void* palloc(struct pool* m_pool) /* 页表中添加虚拟地址_vaddr与物理地址_page_phyaddr的映射 */ static void page_table_add(void* _vaddr, void* _page_phyaddr) /* 分配pg_cnt个页空间,成功则返回起始虚拟地址,失败时返回NULL */ void* malloc_page(enum pool_flags pf, uint32_t pg_cnt) /* 从内核物理内存池中申请pg_cnt页内存,成功则返回其虚拟地址,失败则返回NULL */ void* get_kernel_pages(uint32_t pg_cnt) 我们的总共内存是采用BIOS中断获取的，内存初始函数如下 /* 内存管理部分初始化入口 */ void mem_init() { put_str(\"mem_init start\\n\"); uint32_t mem_bytes_total = (*(uint32_t*)(0xb00)); mem_pool_init(mem_bytes_total); // 初始化内存池 put_str(\"mem_init done\\n\"); } /* 初始化内存池 */ static void mem_pool_init(uint32_t all_mem) { put_str(\" mem_pool_init start\\n\"); uint32_t page_table_size = PG_SIZE * 256; // 页表大小= 1页的页目录表+第0和第768个页目录项指向同一个页表+ // 第769~1022个页目录项共指向254个页表,共256个页框 uint32_t used_mem = page_table_size + 0x100000; // 0x100000为低端1M内存 uint32_t free_mem = all_mem - used_mem; uint16_t all_free_pages = free_mem / PG_SIZE; // 1页为4k,不管总内存是不是4k的倍数, // 对于以页为单位的内存分配策略，不足1页的内存不用考虑了。 uint16_t kernel_free_pages = all_free_pages / 2; uint16_t user_free_pages = all_free_pages - kernel_free_pages; /* 为简化位图操作，余数不处理，坏处是这样做会丢内存。 好处是不用做内存的越界检查,因为位图表示的内存少于实际物理内存*/ uint32_t kbm_length = kernel_free_pages / 8; // Kernel BitMap的长度,位图中的一位表示一页,以字节为单位 uint32_t ubm_length = user_free_pages / 8; // User BitMap的长度. uint32_t kp_start = used_mem; // Kernel Pool start,内核内存池的起始地址 uint32_t up_start = kp_start + kernel_free_pages * PG_SIZE; // User Pool start,用户内存池的起始地址 kernel_pool.phy_addr_start = kp_start; user_pool.phy_addr_start = up_start; kernel_pool.pool_size = kernel_free_pages * PG_SIZE; user_pool.pool_size = user_free_pages * PG_SIZE; kernel_pool.pool_bitmap.btmp_bytes_len = kbm_length; user_pool.pool_bitmap.btmp_bytes_len = ubm_length; /********* 内核内存池和用户内存池位图 *********** * 位图是全局的数据，长度不固定。 * 全局或静态的数组需要在编译时知道其长度， * 而我们需要根据总内存大小算出需要多少字节。 * 所以改为指定一块内存来生成位图. * ************************************************/ // 内核使用的最高地址是0xc009f000,这是主线程的栈地址.(内核的大小预计为70K左右) // 32M内存占用的位图是2k.内核内存池的位图先定在MEM_BITMAP_BASE(0xc009a000)处. kernel_pool.pool_bitmap.bits = (void*)MEM_BITMAP_BASE; /* 用户内存池的位图紧跟在内核内存池位图之后 */ user_pool.pool_bitmap.bits = (void*)(MEM_BITMAP_BASE + kbm_length); /******************** 输出内存池信息 **********************/ put_str(\" kernel_pool_bitmap_start:\");put_int((int)kernel_pool.pool_bitmap.bits); put_str(\" kernel_pool_phy_addr_start:\");put_int(kernel_pool.phy_addr_start); put_str(\"\\n\"); put_str(\" user_pool_bitmap_start:\");put_int((int)user_pool.pool_bitmap.bits); put_str(\" user_pool_phy_addr_start:\");put_int(user_pool.phy_addr_start); put_str(\"\\n\"); /* 将位图置0*/ bitmap_init(&kernel_pool.pool_bitmap); bitmap_init(&user_pool.pool_bitmap); /* 下面初始化内核虚拟地址的位图,按实际物理内存大小生成数组。*/ kernel_vaddr.vaddr_bitmap.btmp_bytes_len = kbm_length; // 用于维护内核堆的虚拟地址,所以要和内核内存池大小一致 /* 位图的数组指向一块未使用的内存,目前定位在内核内存池和用户内存池之外*/ kernel_vaddr.vaddr_bitmap.bits = (void*)(MEM_BITMAP_BASE + kbm_length + ubm_length); kernel_vaddr.vaddr_start = K_HEAP_START; bitmap_init(&kernel_vaddr.vaddr_bitmap); put_str(\" mem_pool_init done\\n\"); } 回顾虚拟地址到物理地址的转换 虚拟地址高10位*4，作为页目录表内的偏移地址，加上目录表的物理地址，就能得到页目录的物理地址。读取页目录表的内容，可以得到页表的物理地址 虚拟地址的中间10位*4，作为页表内的偏移地址，加上步骤1的页表物理地址，将得到页表项的物理地址。读取该页表项的内容，可以得到分配的物理页的地址。 虚拟地址高10位和中间10位分别是PED和PTD的索引值，所以需要乘以4。低12位不是索引值，其范围是0-0xfff,作为页内偏移。步骤2的物理地址加上此偏移，得到最终的物理地址。 实际操作也是如此，当分配的内存时一页的整数倍时，可能要新建页目录项，新建页表，当然每次的内存分配，释放，位图结构是跟着改变着，我们就是user\\_pool,kernel\\_pool两个来进行物理内存池的管理 运行截图 运行 调试 查看虚拟地址到物理地址的映射 查看bitmap内容 低三位是1，说明申请了3个页，符合预期 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-09-05 22:41:18 "},"content/10_process_thread/":{"url":"content/10_process_thread/","title":"10 内核实现线程","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 进程 & 线程 进程PCB CPU执行流 线程 在用户进程中实现线程 线程在内核空间实现 内核空间中实现线程，并验证运行 测试代码和运行截图 进程 & 线程 进程PCB，线程与进程的区别，线程的实现(用户级，内核级) 进程PCB 进程控制块(PCB)是系统为了管理进程设置的一个专门的数据结构。系统用它来记录进程的外部特征，描述进程的运动变化过程。同时，系统可以利用PCB来控制和管理进程，所以说，PCB（进程控制块）是系统感知进程存在的唯一标志。 PCB通常记载进程之相关信息，包括： 程序计数器：接着要运行的指令地址。 进程状态：可以是new、ready、running、waiting或 blocked等。 CPU暂存器：如累加器、索引暂存器（Index register）、堆栈指针以及一般用途暂存器、状况代码等，主要用途在于中断时暂时存储数据，以便稍后继续利用；其数量及类因电脑架构有所差异。 CPU排班法：优先级、排班队列等指针以及其他参数。 存储器管理：如标签页表等。 会计信息：如CPU与实际时间之使用数量、时限、账号、工作或进程号码。 输入输出状态：配置进程使用I/O设备，如磁带机。 CPU执行流 cpu在任务之间切换，这样提高CPU的利用率。 任务就是一段指令流，只有\"指令\"才有执行的能力。 指令流对应于代码，大到可以是整个程序文件，即进程，小到可以是一个功能独立的代码块，即函数，而线程本质上就是函数。 指令流是独立的，它的独立性体现在每个执行流都有自己的械、一套自己的寄存器映像和内存资源，这是 Intel 处理器在硬件上规定的，其实这正是执行流的上下文环境。因此，我们要想构造一个执行流，就要为其提供这一整套的资源。 在任务调度器的眼里，只有执行流才是调度单元，即处理器上运行的每个任务都是调度器给分配的执行流，只要成为执行流就能够独立上处理器运行了，也就是说处理器会专门运行执行流中的指令。 线程 线程是一套机制，此机制可以为一般的代码块创造它所依赖的上下文环境，从而让代码块具有独立性，因此在原理上线程能使一段函数成为调度单元（或称为执行流），使函数能被调度器“认可”，从而能够被专门调度到处理器上执行。这样，函数就可以被加入到线程表中作为调度器的调度单元，从而有机会单独获得处理器资源，也就是说，处理器不是把线程中调用的函数和其他指令混在一块执行的，或者说不是在执行整个进程时顺便执行了该函数，而是单独且专门执行了此函数。 在用户进程中实现线程 线程的调度算法是由用户程序自己实现的，可以根据实际应用情况为某些线程加权调度。 将线程的寄存器映像装载到 CPU 时，可以在用户空间完成，即不用陷入到内核态，这样就免去了进入内核时的入栈及出栈操作。 进程中的某个线程若出现了阻塞（通常是由于系统调用造成的），操作系统不知道进程中存在线程，它以为此进程是传统型进程（单线程进程），因此会将整个进程挂起，即进程中的全部线程都无法运行， 线程在用户空间中实现，线程属于进程自己的\"家务事\"操作系统根本不知道它的存在。这就导致了：如果在用户空间中实现线程，但凡进程中的某个线程开始在处理器上执行后，只要该线程不主动让出处理器，此进程中的其他线程都没机会运行。也就是说，没有保险的机制使线程运行“适时飞即避免单一线程过度使用处理器，而其他线程没有调度的机会。这只能凭借开发人员“人为”地在线程中调用类似pthread_yield 或 pthread_exit 之类的方法使线程发扬“高风亮节”让出处理器使用权，此类方法通过回调方式触发进程内的线程调度器，让调度器有机会选择进程内的其他线程上处理器运行。重复强调：这里所说的“线程让出处理器使用权”，不是将整个进程的处理器使用权通过操作系统调度器交给其他进程，而是将控制权交给此进程自己的线程调度器，由自己的调度器将处理器使用权交给此进程中的下一个线程。 和在内核空间实现相比，只是在内部调度时少了陷入内核的代价，确实相当于提速，但由于整个进程占据处理器的时间片是有限的，这有限的时间片还要再分给内部的线程，所以每个线程执行的时间片非常非常短暂，再加上进程内线程调度器维护线程表、运行调度算法的时间片消耗，反而抵销了内部调度带来的提速。 线程在内核空间实现 相比在用户空间中实现线程，内核提供的线程相当于让进程多占了处理器资源，比如系统中运行有进程 A 和一传统型进程 B，此时进程 A 中显式创建了 3 个线程，这样一来，进程 A 加上主线程便有了 4 个线程，加上进程 B，内核调度器眼中便有了 5 个独立的执行流，尽管其中 4 个都属于进程 A，但对调度器来说这4个线程和进程一样被调度，因此调度器调度完一圈后，进程 A 使用了 80%的处理器资源，这才是真正的提速。 另一方面的优点是当进程中的某一线程阻塞后，由于线程是由内核空间实现的，操作系统是认识线程的，所以就只会阻塞这一个线程，此线程所在进程内的其他线程将不受影响，这又相当于提速了 。 缺点是用户进程需要通过系统调用陷入内核，这多少增加了 一些现场保护的操作，这还是会消耗一些处理器时间，但和上面的大幅度提速相比，这不算什么大事。 内核空间中实现线程，并验证运行 intr_stack定义了程序的中断栈，无论进程还是线程，此结构用于中断发生时保护程序的上下文环境 /*********** 中断栈intr_stack *********** * 此结构用于中断发生时保护程序(线程或进程)的上下文环境: * 进程或线程被外部中断或软中断打断时,会按照此结构压入上下文 * 寄存器, intr_exit中的出栈操作是此结构的逆操作 * 此栈在线程自己的内核栈中位置固定,所在页的最顶端 ********************************************/ struct intr_stack { uint32_t vec_no; // kernel.S 宏VECTOR中push %1压入的中断号 uint32_t edi; uint32_t esi; uint32_t ebp; uint32_t esp_dummy; // 虽然pushad把esp也压入,但esp是不断变化的,所以会被popad忽略 uint32_t ebx; uint32_t edx; uint32_t ecx; uint32_t eax; uint32_t gs; uint32_t fs; uint32_t es; uint32_t ds; /* 以下由cpu从低特权级进入高特权级时压入 */ uint32_t err_code; // err_code会被压入在eip之后 void (*eip) (void); uint32_t cs; uint32_t eflags; void* esp; uint32_t ss; }; 线程栈，PCB /* 自定义通用函数类型,它将在很多线程函数中做为形参类型 */ typedef void thread_func(void*); /* 进程或线程的状态 */ enum task_status { TASK_RUNNING, TASK_READY, TASK_BLOCKED, TASK_WAITING, TASK_HANGING, TASK_DIED }; /*********** 线程栈thread_stack *********** * 线程自己的栈,用于存储线程中待执行的函数 * 此结构在线程自己的内核栈中位置不固定, * 用在switch_to时保存线程环境。 * 实际位置取决于实际运行情况。 ******************************************/ struct thread_stack { uint32_t ebp; uint32_t ebx; uint32_t edi; uint32_t esi; /* 线程第一次执行时,eip指向待调用的函数kernel_thread 其它时候,eip是指向switch_to的返回地址*/ void (*eip) (thread_func* func, void* func_arg); /***** 以下仅供第一次被调度上cpu时使用 ****/ /* 参数unused_ret只为占位置充数为返回地址 */ void (*unused_retaddr); thread_func* function; // 由Kernel_thread所调用的函数名 void* func_arg; // 由Kernel_thread所调用的函数所需的参数 }; /* 进程或线程的pcb,程序控制块 */ struct task_struct { uint32_t* self_kstack; // 各内核线程都用自己的内核栈 enum task_status status; uint8_t priority; // 线程优先级 char name[16]; uint32_t stack_magic; // 用这串数字做栈的边界标记,用于检测栈的溢出 }; void thread_create(struct task_struct* pthread, thread_func function, void* func_arg); void init_thread(struct task_struct* pthread, char* name, int prio); struct task_struct* thread_start(char* name, int prio, thread_func function, void* func_arg); call 和 ret 汇编理解参考如下 http://blog.csdn.net/qq_26437925/article/details/70947174 线程相关函数 /* 由kernel_thread去执行function(func_arg) */ static void kernel_thread(thread_func* function, void* func_arg) { function(func_arg); } /* 初始化线程栈thread_stack,将待执行的函数和参数放到thread_stack中相应的位置 */ void thread_create(struct task_struct* pthread, thread_func function, void* func_arg) { /* 先预留中断使用栈的空间,可见thread.h中定义的结构 */ pthread->self_kstack -= sizeof(struct intr_stack); /* 再留出线程栈空间,可见thread.h中定义 */ pthread->self_kstack -= sizeof(struct thread_stack); struct thread_stack* kthread_stack = (struct thread_stack*)pthread->self_kstack; kthread_stack->eip = kernel_thread; kthread_stack->function = function; kthread_stack->func_arg = func_arg; kthread_stack->ebp = kthread_stack->ebx = kthread_stack->esi = kthread_stack->edi = 0; } /* 初始化线程基本信息 */ void init_thread(struct task_struct* pthread, char* name, int prio) { memset(pthread, 0, sizeof(*pthread)); strcpy(pthread->name, name); pthread->status = TASK_RUNNING; pthread->priority = prio; /* self_kstack是线程自己在内核态下使用的栈顶地址 */ pthread->self_kstack = (uint32_t*)((uint32_t)pthread + PG_SIZE); pthread->stack_magic = 0x19870916; // 自定义的魔数 } /* 创建一优先级为prio的线程,线程名为name,线程所执行的函数是function(func_arg) */ struct task_struct* thread_start(char* name, int prio, thread_func function, void* func_arg) { /* pcb都位于内核空间,包括用户进程的pcb也是在内核空间 */ struct task_struct* thread = get_kernel_pages(1); init_thread(thread, name, prio); thread_create(thread, function, func_arg); asm volatile (\"movl %0, %%esp; pop %%ebp; pop %%ebx; pop %%edi; pop %%esi; ret\" : : \"g\" (thread->self_kstack) : \"memory\"); return thread; } PCB从内核空间中申请一页内存（即4096字节），*thread指向PCB最低地址 /* pcb都位于内核空间,包括用户进程的pcb也是在内核空间 */ struct task_struct* thread = get_kernel_pages(1); 执行线程函数时，eip指向kernel_thread,处理器进入kernel_thread函数体时，栈顶为返回地址，栈顶地址加上4为参数function,栈顶地址加上8为参数func_arg /* 由kernel_thread去执行function(func_arg) */ static void kernel_thread(thread_func* function, void* func_arg) { function(func_arg); } 使得PCB结构指针thread的thread->sel_kstack作为栈顶 movl %0, %esp 弹出栈，这几个寄存器在线程栈中定义了的,初始为0，线程执行过程中这几个寄存器值变化。在函数调用时，ebp,ebx，edi,esi和esp这5个寄存器归主调用函数所用，其余寄存器归被调用函数所用，esp是栈顶，其值由函数调用约定来保证，所以线程栈中只保存了4个寄存器的值，在函数切换时，这4个寄存器的值会被保存起来。 pop %%ebp; pop %%ebx; pop %%edi; pop %%esi; /* 初始化线程栈thread_stack,将待执行的函数和参数放到thread_stack中相应的位置 */ void thread_create(struct task_struct* pthread, thread_func function, void* func_arg) { /* 先预留中断使用栈的空间,可见thread.h中定义的结构 */ pthread->self_kstack -= sizeof(struct intr_stack); /* 再留出线程栈空间,可见thread.h中定义 */ pthread->self_kstack -= sizeof(struct thread_stack); struct thread_stack* kthread_stack = (struct thread_stack*)pthread->self_kstack; kthread_stack->eip = kernel_thread; kthread_stack->function = function; kthread_stack->func_arg = func_arg; kthread_stack->ebp = kthread_stack->ebx = kthread_stack->esi = kthread_stack->edi = 0; } ret会把栈顶数据作为返回地址送给CPU的eip去执行，而此时栈顶就是kernel_thread函数(再thread_create函数中kernel_thread赋值给了eip)，kernel_thread会去执行线程函数function(func_arg),这样线程就开始执行了。 测试代码和运行截图 #include \"print.h\" #include \"init.h\" #include \"thread.h\" void k_thread_a(void*); int main(void) { put_str(\"I am kernel\\n\"); init_all(); thread_start(\"k_thread_a\", 31, k_thread_a, \"argA \"); while(1); return 0; } /* 在线程中运行的函数 */ void k_thread_a(void* arg) { /* 用void*来通用表示参数,被调用的函数知道自己需要什么类型的参数,自己转换再用 */ char* para = arg; while(1) { put_str(para); } } 运行截图：线程中不断的打印参数 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-02 15:58:06 "},"content/11_thread_schedule/":{"url":"content/11_thread_schedule/","title":"11 多线程调度","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 线程调度 线程和线程管理设计 线程调度 线程，PCB结构，函数 测试程序运行&验证截图 线程调度 中断 上下文保护 轮询法实现线程调度 线程和线程管理设计 数据结构主要是实现双向链表。 多线程维持了两个链表，一个是全部线程链表，一个是就绪线程链表。 /* 进程或线程的状态 */ enum task_status { TASK_RUNNING, TASK_READY, TASK_BLOCKED, TASK_WAITING, TASK_HANGING, TASK_DIED }; 就绪队列中的线程可以直接在处理器上运行，当线程得不到CPU或者被阻塞了就需要从就绪队列中移除。 线程被换下: 时间片到了；时间片未到，被阻塞了； 调度器按照线程队列先进先出的顺序，把就绪队列中的第一个线程作为下一个要运行的线程。 采用ticks（时间片）和priority（线程优先级）配合使用； 优先级越高，那么执行时间就越长，当一个线程的ticks减少为0时，就需要被换下了，然后被重新赋予priority,下次再被调用。 线程调度 调度器schedule就是根据线程运行状态将其从处理器上换上换下，所以主要任务是读写就绪对垒，增删里面的结点。 线程在处理器上的执行时间有ticks决定，而在初始一个线程的时候会赋予一个线程优先级prioriy，ticks也赋值成了priority,这样优先级越高，线程执行时间就越长。系统会有时钟中断，每一次中断ticks减少1，当ticks减少至0是，时钟中断处理程序就调用调度器schedule,把该线程换下，选择另一个线程上CPU 完成整个调度需要如下的3部分： 时钟中断处理函数 调度器shedule 任务切换函数switch_to 函数切换涉及到任务的上下文保护 中断发生时，当前运行的任务（线程或用户进程〉被打断，随后会去执行中断处理程序，不管当前任务在中断前的特权级是什么，执行中断处理程序时肯定都是 0 特权级。现在咱们已经达成共识，任务的代码包括用户代码＋内核代码，即使是部分用户代码，因此进入中断后所执行的一切内核代码也依然属于当前任务，只是由内核来提供这一部分而己。 上下文保护第一个部分：保存任务进入中断前的全部寄存器，目的是能让任务恢复到执中断前的状态。 上下文保护第二部分：保存API固定的寄存器，主要是esi,edi,ebp,esp这4个寄存器，目的是让任务恢复执行在任务切换发生时剩下尚未执行的内核代码，保证顺利走到退出中断的出口，利用第一部分保护的寄存器环境彻底恢复任务。 switch.S [bits 32] section .text global switch_to switch_to: ;栈中此处是返回地址 push esi push edi push ebx push ebp mov eax, [esp + 20] ; 得到栈中的参数cur, cur = [esp+20] mov [eax], esp ; 保存栈顶指针esp. task_struct的self_kstack字段, ; self_kstack在task_struct中的偏移为0, ; 所以直接往thread开头处存4字节便可。 ;------------------ 以上是备份当前线程的环境，下面是恢复下一个线程的环境 ---------------- mov eax, [esp + 24] ; 得到栈中的参数next, next = [esp+24] mov esp, [eax] ; pcb的第一个成员是self_kstack成员,用来记录0级栈顶指针, ; 用来上cpu时恢复0级栈,0级栈中保存了进程或线程所有信息,包括3级栈指针 pop ebp pop ebx pop edi pop esi ret ; 返回到上面switch_to下面的那句注释的返回地址, ; 未由中断进入,第一次执行时会返回到kernel_thread 线程，PCB结构，函数 /* 进程或线程的pcb,程序控制块 */ struct task_struct { uint32_t* self_kstack; // 各内核线程都用自己的内核栈 enum task_status status; char name[16]; uint8_t priority; uint8_t ticks; // 每次在处理器上执行的时间嘀嗒数 /* 此任务自上cpu运行后至今占用了多少cpu嘀嗒数, * 也就是此任务执行了多久*/ uint32_t elapsed_ticks; /* general_tag的作用是用于线程在一般的队列中的结点 */ struct list_elem general_tag; /* all_list_tag的作用是用于线程队列thread_all_list中的结点 */ struct list_elem all_list_tag; uint32_t* pgdir; // 进程自己页表的虚拟地址 uint32_t stack_magic; // 用这串数字做栈的边界标记,用于检测栈的溢出 }; thread_stack /*********** 线程栈thread_stack *********** * 线程自己的栈,用于存储线程中待执行的函数 * 此结构在线程自己的内核栈中位置不固定, * 用在switch_to时保存线程环境。 * 实际位置取决于实际运行情况。 ******************************************/ struct thread_stack { uint32_t ebp; uint32_t ebx; uint32_t edi; uint32_t esi; /* 线程第一次执行时,eip指向待调用的函数kernel_thread 其它时候,eip是指向switch_to的返回地址*/ void (*eip) (thread_func* func, void* func_arg); /***** 以下仅供第一次被调度上cpu时使用 ****/ /* 参数unused_ret只为占位置充数为返回地址 */ void (*unused_retaddr); thread_func* function; // 由Kernel_thread所调用的函数名 void* func_arg; // 由Kernel_thread所调用的函数所需的参数 }; 有个主线程问题就是: mbr->loader->main，这是一直运行的主程序线程，其它线程都只是在创建过程中执行的。 /* 将kernel中的main函数完善为主线程 */ static void make_main_thread(void) { /* 因为main线程早已运行,咱们在loader.S中进入内核时的mov esp,0xc009f000, 就是为其预留了tcb,地址为0xc009e000,因此不需要通过get_kernel_page另分配一页*/ main_thread = running_thread(); init_thread(main_thread, \"main\", 31); /* main函数是当前线程,当前线程不在thread_ready_list中, * 所以只将其加在thread_all_list中. */ ASSERT(!elem_find(&thread_all_list, &main_thread->all_list_tag)); list_append(&thread_all_list, &main_thread->all_list_tag); } /* 创建一优先级为prio的线程,线程名为name,线程所执行的函数是function(func_arg) */ struct task_struct* thread_start(char* name, int prio, thread_func function, void* func_arg) { /* pcb都位于内核空间,包括用户进程的pcb也是在内核空间 */ struct task_struct* thread = get_kernel_pages(1); init_thread(thread, name, prio); thread_create(thread, function, func_arg); /* 确保之前不在队列中 */ ASSERT(!elem_find(&thread_ready_list, &thread->general_tag)); /* 加入就绪线程队列 */ list_append(&thread_ready_list, &thread->general_tag); /* 确保之前不在队列中 */ ASSERT(!elem_find(&thread_all_list, &thread->all_list_tag)); /* 加入全部线程队列 */ list_append(&thread_all_list, &thread->all_list_tag); return thread; } /* 初始化线程环境 */ void thread_init(void) { put_str(\"thread_init start\\n\"); list_init(&thread_ready_list); list_init(&thread_all_list); /* 将当前main函数创建为线程 */ make_main_thread(); put_str(\"thread_init done\\n\"); } 测试程序运行&验证截图 #include \"print.h\" #include \"init.h\" #include \"thread.h\" #include \"interrupt.h\" void k_thread_a(void*); void k_thread_b(void*); int main(void) { put_str(\"I am kernel\\n\"); init_all(); thread_start(\"k_thread_a\", 8, k_thread_a, \"arguA \"); thread_start(\"k_thread_b\", 31, k_thread_b, \"arguB \"); intr_enable();// 打开中断,使时钟中断起作用 while(1) { put_str(\"Main \"); }; return 0; } /* 在线程中运行的函数 */ void k_thread_a(void* arg) { /* 用void*来通用表示参数,被调用的函数知道自己需要什么类型的参数,自己转换再用 */ char* para = arg; while(1) { put_str(para); } } /* 在线程中运行的函数 */ void k_thread_b(void* arg) { /* 用void*来通用表示参数,被调用的函数知道自己需要什么类型的参数,自己转换再用 */ char* para = arg; while(1) { put_str(para); } } 注意到：本例程序运行有GP异常，这是由于临界区代码的资源竞争（屏幕输出，几个线程竞争资源造成的，需要利用同步，互斥等去处理） Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-02 16:05:11 "},"content/12_lock/":{"url":"content/12_lock/","title":"12 锁&信号量","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 解决多线程竞争 临界区，竞争条件，互斥 分析上一小结的线程竞争问题 信号量 信号量，PV操作 实现信号量 利用锁实现终端多线程正常输出 编写主函数验证 解决多线程竞争 临界区，互斥，信号量，锁等 临界区，竞争条件，互斥 公共资源 可以是公共内存、公共文件、公共硬件等，总之是被很多任务共享的一套资源。 临界区 程序要想使用某些资源，必然通过一些指令去访问这些资源，若多个任务都访问同一公共资源，那么各任务中访问公共资源的指令代码组成的区域就称为临界区。怕有同学看得不仔细，强调一下，临界区是指程序中那些访问公共资源的指令代码，即临界区是指令，并不是受访的静态公共资源。 互斥 互斥也可称为排它，是指某一时刻公共资源只能被 1 个任务独享，即不允许多个任务同时出现在自己的临界区中。公共资源在任意时刻只能被一个任务访问，即只能有一个任务在自己的临界区中执行，其它任务想访问公共资源时，必须等待当前公共资源的访问者完全执行完它自己的临界区代码后（即使用完资源后）才能开始访问。 竞争条件 竞争条件是指多个任务以非互斥的方式同时进入临界区，大家对公共资源的访问是以竞争的方式并行进行的，因此公共资源的最终状态依赖于这些任务的临界区中的微操作执行次序。 当多个任务“同时”读写公共资源时，也就是多个任务“同时”执行它们各自临界区中的代码时，它们以混杂井行的方式访问同一资源，因此后面任务会将前一任务的结果覆盖，最终公共资源的结果取决于所有任务的执行时序。这里所说的“同时”也可以指多任务伪并行，总之是指一个任务在自己的临界区中读写公共资源，还没来得及出来（彻底执行完临界区所有代码），另一小任务也进入了它自己的临界区去访问同一资源。 分析上一小结的线程竞争问题 线程 k_tbread a、 k_tbread_b 和主线程 每个线程都调用 put_char 函数来打印字符， put_char的功能是访问公共资源显存及光标寄存器 临界区 put_char 中的指令不是一条，而是很多；因此对公共资源的访问无法一下子执行彻底。当多个线程都在临界区时，受访的资源是同一个，加之多个线程又是伪井行，后面进入临界区的线程必然会覆盖前面所有线程的成果，再者，即使多个线程是真并行执行，对于访问共享资源也会有个前后顺序，因此显存和光标寄存器这两个公共资源的状态取决于所有线程的访问时序 多线程访问公共资源时出问题的原因是产生了竞争条件，也就是多个任务同时出现在自己的临界区 。 为避免产生竞争条件，必须保证任意时刻只能有一个任务处于临界区。因此，只要保证各线程自己临界区中的所有代码都是原子操作，即临界区中的指令要么一条不做，要么一气呵成全部执行完，执行期间绝对不能被换下处理器 信号量 同步概念 --> 信号量 同步一般是指合作单位之间为协作完成某项工作而共同遵守的工作步调，强调的是配合时序，就像十字路口的红绿灯，只有在绿灯亮起的情况下司机才能踩油门把车往前开，这就是一种同步，绿灯不亮就开车的话容易引起交通事故，这就是在十字路口这种事故多发地带用红绿灯同步交通的目的。同步简单来说就是不能随时随意工作，工作必须在某种条件具备的情况下才能开始，工作条件具备的时间顺序就是时序。（红绿灯就类似后文要介绍的信号量） 线程同步 线程同步的目的是不管线程如何混杂、穿插地执行，都不会影响结果的正确性。但线程不像人那样有判断“配合时序”的意识，它的执行会很随意，这就使合作出错成为必然。因此，当多个线程访问同一公共资源时（当然这也属于线程合作〉，为了保证结果正确，必然要用一套额外的机制来控制它们的工作步调，也就是使线程们同步工作。这里引入信号量 信号量，PV操作 增加操作(up),包括两个微操作 将信号量的值加 l 唤醒在此信号量上等待的线程 减少操作(down),包括三个子操作 判断信号量是否大于 0 若信号量大于 0 ，则将信号量减 1 若信号量等于 0 ，当前线程将自己阻塞，以在此信号量上不断的等待 注：信号量的PV操作时都为原子操作（因为它需要保护临界资源）；原子操作指指令的操作行为是不会被打断的，原子性的 信号量的初值代表是信号资源的累积量，也就是剩余量，若初值为 1 的话，它的取值就只能为 0 和 1，这便称为二元信号量，我们可以利用二元信号量来实现锁。 阻塞是线程自己发出的动作，也就是线程自己阻塞自己，并不是被别人阻塞的，阻塞是线程主动的行为。被阻塞的线程是由别人来唤醒的，唤醒是被动的操作。 线程阻塞 /* 当前线程将自己阻塞,标志其状态为stat. */ void thread_block(enum task_status stat) { /* stat取值为TASK_BLOCKED,TASK_WAITING,TASK_HANGING,也就是只有这三种状态才不会被调度*/ ASSERT(((stat == TASK_BLOCKED) || (stat == TASK_WAITING) || (stat == TASK_HANGING))); enum intr_status old_status = intr_disable(); struct task_struct* cur_thread = running_thread(); cur_thread->status = stat; // 置其状态为stat schedule(); // 将当前线程换下处理器 /* 待当前线程被解除阻塞后才继续运行下面的intr_set_status */ intr_set_status(old_status); } 线程唤醒 /* 将线程pthread解除阻塞 */ void thread_unblock(struct task_struct* pthread) { enum intr_status old_status = intr_disable(); ASSERT(((pthread->status == TASK_BLOCKED) || (pthread->status == TASK_WAITING) || (pthread->status == TASK_HANGING))); if (pthread->status != TASK_READY) { ASSERT(!elem_find(&thread_ready_list, &pthread->general_tag)); if (elem_find(&thread_ready_list, &pthread->general_tag)) { PANIC(\"thread_unblock: blocked thread in ready_list\\n\"); } list_push(&thread_ready_list, &pthread->general_tag); // 放到队列的最前面,使其尽快得到调度 pthread->status = TASK_READY; } intr_set_status(old_status); } 实现信号量 /* 信号量结构 */ struct semaphore { uint8_t value; struct list waiters; }; /* 锁结构 */ struct lock { struct task_struct* holder; // 锁的持有者 struct semaphore semaphore; // 用二元信号量实现锁 uint32_t holder_repeat_nr; // 锁的持有者重复申请锁的次数 }; 初始信号量,锁 /* 初始化信号量 */ void sema_init(struct semaphore* psema, uint8_t value) { psema->value = value; // 为信号量赋初值 list_init(&psema->waiters); //初始化信号量的等待队列 } /* 初始化锁plock */ void lock_init(struct lock* plock) { plock->holder = NULL; plock->holder_repeat_nr = 0; sema_init(&plock->semaphore, 1); // 信号量初值为1 } 信号PV，锁的获取释放(利用中断) /* 信号量down操作 */ void sema_down(struct semaphore* psema) { /* 关中断来保证原子操作 */ enum intr_status old_status = intr_disable(); while(psema->value == 0) { // 若value为0,表示已经被别人持有 ASSERT(!elem_find(&psema->waiters, &running_thread()->general_tag)); /* 当前线程不应该已在信号量的waiters队列中 */ if (elem_find(&psema->waiters, &running_thread()->general_tag)) { PANIC(\"sema_down: thread blocked has been in waiters_list\\n\"); } /* 若信号量的值等于0,则当前线程把自己加入该锁的等待队列,然后阻塞自己 */ list_append(&psema->waiters, &running_thread()->general_tag); thread_block(TASK_BLOCKED); // 阻塞线程,直到被唤醒 } /* 若value为1或被唤醒后,会执行下面的代码,也就是获得了锁。*/ psema->value--; ASSERT(psema->value == 0); /* 恢复之前的中断状态 */ intr_set_status(old_status); } /* 信号量的up操作 */ void sema_up(struct semaphore* psema) { /* 关中断,保证原子操作 */ enum intr_status old_status = intr_disable(); ASSERT(psema->value == 0); if (!list_empty(&psema->waiters)) { struct task_struct* thread_blocked = elem2entry(struct task_struct, general_tag, list_pop(&psema->waiters)); thread_unblock(thread_blocked); } psema->value++; ASSERT(psema->value == 1); /* 恢复之前的中断状态 */ intr_set_status(old_status); } /* 获取锁plock */ void lock_acquire(struct lock* plock) { /* 排除曾经自己已经持有锁但还未将其释放的情况。*/ if (plock->holder != running_thread()) { sema_down(&plock->semaphore); // 对信号量P操作,原子操作 plock->holder = running_thread(); ASSERT(plock->holder_repeat_nr == 0); plock->holder_repeat_nr = 1; } else { plock->holder_repeat_nr++; } } /* 释放锁plock */ void lock_release(struct lock* plock) { ASSERT(plock->holder == running_thread()); if (plock->holder_repeat_nr > 1) { plock->holder_repeat_nr--; return; } ASSERT(plock->holder_repeat_nr == 1); plock->holder = NULL; // 把锁的持有者置空放在V操作之前 plock->holder_repeat_nr = 0; sema_up(&plock->semaphore); // 信号量的V操作,也是原子操作 } 利用锁实现终端多线程正常输出 虚拟终端 虚拟终端就是我们熟知的terminal，据说 tty 原指电传打字机，即 TeleTYpes，它是一种用打字机键盘通过串行线发送和接收信息的设备，后来被键盘和显示器取代了，因此称为 tty 翻译为终端更合适。我们登录系统后，就会在后台运行一个 tty 进程 现在咱们操作 Linux，都是通过 ssh 远程连上去，除了去机房外，很少有直接在机器上登录系统的。包括我自己装虚拟机的时候，都是另装个 ssh 工具连接到虚拟机，习惯了 ssh 客户端的便利。顺便说一下，这种从远程连接到 Linux 主机的终端称为pts(linux who命令可以查看) 互斥的实现控制台输出 static struct lock console_lock; // 控制台锁 /* 初始化终端 */ void console_init() { lock_init(&console_lock); } /* 获取终端 */ void console_acquire() { lock_acquire(&console_lock); } /* 释放终端 */ void console_release() { lock_release(&console_lock); } /* 终端中输出字符串 */ void console_put_str(char* str) { console_acquire(); put_str(str); console_release(); } /* 终端中输出字符 */ void console_put_char(uint8_t char_asci) { console_acquire(); put_char(char_asci); console_release(); } /* 终端中输出16进制整数 */ void console_put_int(uint32_t num) { console_acquire(); put_int(num); console_release(); } 文件中定义的 console_lock 是终端锁，对终端的所操作都是围绕申请这个锁展开的。它必须是全局 唯一的，因此类型是静态 static。 /*负责初始化所有模块 */ void init_all() { put_str(\"init_all\\n\"); idt_init(); // 初始化中断 mem_init(); // 初始化内存管理系统 thread_init(); // 初始化线程相关结构 timer_init(); // 初始化PIT console_init(); //控制台初始化最好放在开中断之前 } 编写主函数验证 main.c void k_thread_a(void*); void k_thread_b(void*); int main(void) { put_str(\"I am kernel\\n\"); init_all(); thread_start(\"k_thread_a\", 31, k_thread_a, \"argA \"); thread_start(\"k_thread_b\", 8, k_thread_b, \"argB \"); intr_enable(); while(1) { console_put_str(\"Main \"); }; return 0; } /* 在线程中运行的函数 */ void k_thread_a(void* arg) { /* 用void*来通用表示参数,被调用的函数知道自己需要什么类型的参数,自己转换再用 */ char* para = arg; while(1) { console_put_str(para); } } /* 在线程中运行的函数 */ void k_thread_b(void* arg) { /* 用void*来通用表示参数,被调用的函数知道自己需要什么类型的参数,自己转换再用 */ char* para = arg; while(1) { console_put_str(para); } } 将不再报错，打印结果也是很整齐的打印的 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-09-05 18:48:24 "},"content/12_lock/linux_mutex.html":{"url":"content/12_lock/linux_mutex.html","title":"pthread_mutex_t","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Linux mutex pthreadmutext 的使用例子 Linux mutex Operation-Systems designers build software tools to solve the critical-section problem. The simplest of these tools is the mutex lock. A process must acquire the lock before entering a critical section; It must release the lock when it exists the critical section. 进入临界区必须获取锁，其它线程必须等待；离开临界区必须要释放锁 进入和离开必须是原子操作（Atomic operations mean the operation can not be interrupted while it's running.）如硬件指令：test_and_set(), compare_and_swap()就是原子操作的 自旋操作：忙式等待，占用CPU执行空循环 缺点：占用CPU，浪费CPU周期 优点：没有上线文切换，多处理器系统中，那么可以在一个核中自旋，自旋更有优势 pthread_mutex_t 的使用例子 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-09-07 08:50:30 "},"content/12_lock/linux_semaphore.html":{"url":"content/12_lock/linux_semaphore.html","title":"linux信号量实践","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Linux 信号量实践 信号量实现生产者消费者 伪代码 linux c代码实现 Linux 信号量实践 linux man semop NAME semop, semtimedop - System V semaphore operations SYNOPSIS #include #include #include int semop(int semid, struct sembuf *sops, size_t nsops); int semtimedop(int semid, struct sembuf *sops, size_t nsops, const struct timespec *timeout); Feature Test Macro Requirements for glibc (see feature_test_macros(7)): semtimedop(): _GNU_SOURCE DESCRIPTION Each semaphore in a System V semaphore set has the following associated values: unsigned short semval; /* semaphore value */ unsigned short semzcnt; /* # waiting for zero */ unsigned short semncnt; /* # waiting for increase */ pid_t sempid; /* ID of process that did last op */ 信号量实现生产者消费者 伪代码 semaphore mutex=1; //临界区互斥信号量 semaphore empty=n; //空闲缓冲区，初始值为buffer的大小 semaphore full=0; //缓冲区初始化为空 producer () { //生产者进程 while(1){ produce an item in nextp; //生产数据 P(empty); //获取空缓冲区单元 P(mutex); //进入临界区. add nextp to buffer; //将数据放入缓冲区 V(mutex); //离开临界区,释放互斥信号量 V(full); //满缓冲区数加1 } } consumer () { //消费者进程 while(1){ P(full); //获取满缓冲区单元 P(mutex); // 进入临界区 remove an item from buffer; //从缓冲区中取出数据 V (mutex); //离开临界区，释放互斥信号量 V (empty) ; //空缓冲区数加1 consume the item; //消费数据 } } linux c代码实现 信号量+互斥锁实现生产者，消费者问题 test.cpp #include #include // sleep #include #include\"semaphore.h\" using namespace std; #define N 5 semaphore mutex(\"/\", 1); // 临界区互斥信号量 semaphore empty(\"/home\", N); // 记录空缓冲区数，初值为N semaphore full(\"/home/john\",0); // 记录满缓冲区数，初值为0 int buffer[N]; // 缓冲区，大小为N int i=0; int j=0; void* producer(void* arg) { empty.P(); // empty减1 mutex.P(); buffer[i] = 10 + rand() % 90; printf(\"Producer %d write Buffer[%d]: %d\\n\",(int)arg,i+1,buffer[i]); i = (i+1) % N; mutex.V(); full.V(); // full加1 return arg; } void* consumer(void* arg) { full.P(); // full减1 mutex.P(); printf(\" \\033[1;31m\"); printf(\"Consumer %d read Buffer[%d]: %d\\n\",(int)arg,j+1,buffer[j]); printf(\"\\033[0m\"); j = (j+1) % N; mutex.V(); empty.V(); // empty加1 return arg; } int main() { pthread_t id[10]; // 开10个生产者线程，10个消费者线程 for(int k=0; k semaphore.h 定义信号量类，以及P，V操作 #include #include #include #include using namespace std; // 联合体，用于semctl初始化 union semun { int val; /*for SETVAL*/ struct semid_ds *buf; unsigned short *array; }; class semaphore { private: int sem_id; //信号量ID，内核中创建 int init_sem(int); public: semaphore(const char*, int); /*构造函数*/ ~semaphore(); /*析构函数*/ void P(); /*P操作*/ void V(); /*V操作*/ }; semaphore.cpp #include\"semaphore.h\" semaphore::semaphore(const char* path, int value) { key_t key; /*获取key值*/ if((key = ftok(path, 'z')) 附：Makefile .PHONY: build clean CC=g++ HEADERS=-I. DEBUG=-g -ggdb WALL=-Wall -W CFLAGS=$(WALL) $(DEBUG) L_CC=$(CC) $(CFLAGS) $(HEADERS) test:test.o semaphore.o $(L_CC) $^ -o $@ -lpthread %.o:%.cpp $(L_CC) -c $ Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-09-05 17:23:45 "},"content/13_input/":{"url":"content/13_input/","title":"13 键盘输入","keywords":"","body":"键盘输入 理解键盘输入，驱动程序概念即可 键盘输入 键盘是个独立的设备，在它内部有个叫作键盘编码器的芯片，通常是 Intel 8048 或兼容芯片，它的作用是：每当键盘上发生按键操作，它就向键盘控制器报告哪个键被按下，按键是否弹起。 这个键盘控制器可并不在键盘内部，它在主机内部的主板上，通常是 Intel 8042 或兼容芯片，它的作用是接收来自键盘编码器的按键信息，将其解码后保存，然后向中断代理发中断，之后处理器执行相应的中断处理程序读入 8042 处理保存过的按键信息。 键盘扫描码：按键·数值，键盘上的每一个键都有数值 一个键的状态要么是按下，要么是弹起，因此一个键便有两个编码，按键被按下时的编码叫通码，也就是表示按键上的触点接通了内部电路，使硬件产生了一个码，故通码也称为 makecode。按键在被按住不松手时会持续产生相同的码，直到按键被松开时才终止，因此按键被松开弹起时产生的编码叫断码，也就是电路被断开了，不再持续产生码了，故断码也称为 breakcode。一个键的扫描码是由通码和断码组成的 按键的表现行为是字符处理程序负责的，键盘的中断处理程序便充当了字符处理程序。 一般的字符处理程序使用字符编码来处理字符，比如 ASCII 码，因此我们可以在中断处理程序中将空格的扫描码 Ox39转换成 ASCII 码 Ox20，然后将 ASCII 码 Ox20 交给我们的 put_char 函数，将 ASCII 码写入显存，也就是输出到屏幕。因此，按下空格键可以在屏幕上输出一个空格，就是这么来的。 驱动程序 在计算机中，硬件是用软件来交互的，想让硬件做什么，必须通过软件的方式告诉它 。 硬件为方便软件对它的“调遣”，它为软件提供了接口，这通常是通过 IO 指令进行一堆复杂的寄存器设置，然后通过读取寄存器检测相应的状态，然后再进行数据交换 。 虽然这己大大方便了我们对硬件的控制，但我们依然是“懒惰的”，不希望每次找硬件帮忙时都做这种重复性的体力劳动，这种很“直白地”寄存器控制指令显然还方便得不够 。 我们不想要“过程”，只想要个“结果”。 为了方便获取“结果”，我们将这些复杂的硬件控制指令封装成一个过程，每次只把对破件的操作需求提交给此过程，由此过程实施底层的控制细节，然后返回给调用者一个结果，这个直接同底层硬件打交道的过程便是驱动程序 。 程序验证 #include \"init.h\" #include \"print.h\" #include \"interrupt.h\" #include \"timer.h\" #include \"memory.h\" #include \"thread.h\" #include \"console.h\" #include \"keyboard.h\" /*负责初始化所有模块 */ void init_all() { put_str(\"init_all\\n\"); idt_init(); // 初始化中断 mem_init(); // 初始化内存管理系统 thread_init(); // 初始化线程相关结构 timer_init(); // 初始化PIT console_init(); //控制台初始化最好放在开中断之前 keyboard_init(); // 键盘初始化 } 输入字符等进行键盘输入验证，查看效果 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-09-05 17:24:19 "},"content/14_input_buffer/":{"url":"content/14_input_buffer/","title":"14 缓冲区","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 缓冲区 生产者/消费者问题实践 缓冲区 在键盘上操作是为了与系统进行交互，交互的过程一般是键入各种 shell 命令，然后 shell 解析并执行。shell 命令是由多个字符组成的，并且要以回车键结束，因此咱们在键入命令的过程中，必须要找个缓冲区把己键入的信息存起来，当凑成完整的命令名时再一并由其它模块处理。 生产者/消费者问题实践 缓冲区中有数据时，消费者可以消费；缓冲区有空位时，生产者可以生成（信号量可以解决生产者消费者问题） 利用双向链表实现环形缓冲区 数据结构和方法 #define bufsize 64 /* 环形队列 */ struct ioqueue { // 生产者消费者问题 struct lock lock; /* 生产者,缓冲区不满时就继续往里面放数据, * 否则就睡眠,此项记录哪个生产者在此缓冲区上睡眠。*/ struct task_struct* producer; /* 消费者,缓冲区不空时就继续从往里面拿数据, * 否则就睡眠,此项记录哪个消费者在此缓冲区上睡眠。*/ struct task_struct* consumer; char buf[bufsize]; // 缓冲区大小 int32_t head; // 队首,数据往队首处写入 int32_t tail; // 队尾,数据从队尾处读出 }; void ioqueue_init(struct ioqueue* ioq); bool ioq_full(struct ioqueue* ioq); bool ioq_empty(struct ioqueue* ioq); /* 消费者从ioq队列中获取一个字符 */ char ioq_getchar(struct ioqueue* ioq); /* 生产者往ioq队列中写入一个字符byte */ void ioq_putchar(struct ioqueue* ioq, char byte); 让键盘缓冲区成为全局的，生产消费都操作 主程序验证 #include \"print.h\" #include \"init.h\" #include \"thread.h\" #include \"interrupt.h\" #include \"console.h\" /* 临时为测试添加 */ #include \"ioqueue.h\" #include \"keyboard.h\" void k_thread_a(void*); void k_thread_b(void*); int main(void) { put_str(\"I am kernel\\n\"); init_all(); thread_start(\"consumer_a\", 31, k_thread_a, \" A_\"); thread_start(\"consumer_b\", 31, k_thread_b, \" B_\"); intr_enable(); while(1); return 0; } /* 在线程中运行的函数 */ void k_thread_a(void* arg) { while(1) { enum intr_status old_status = intr_disable(); if (!ioq_empty(&kbd_buf)) { console_put_str(arg); char byte = ioq_getchar(&kbd_buf); console_put_char(byte); } intr_set_status(old_status); } } /* 在线程中运行的函数 */ void k_thread_b(void* arg) { while(1) { enum intr_status old_status = intr_disable(); if (!ioq_empty(&kbd_buf)) { console_put_str(arg); char byte = ioq_getchar(&kbd_buf); console_put_char(byte); } intr_set_status(old_status); } } 键盘不断的输入字母p,，屏幕交替的输出A_q B_q,ioqueue完成了缓冲区。 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-09-05 17:25:03 "},"content/15_user_process/":{"url":"content/15_user_process/","title":"15 指令特权级，用户进程引入","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 指令特权级&用户进程 特权级 任务切换 实现用户进程 内核中实现线程回顾 用户进程 特权级0 到 特权级3 用户进程的内存空间分布 C程序内存空间分布 附：虚拟空间映射 C程序为什么进行分段？ 指令特权级&用户进程 用户进程的实现 特权级认识 用户进程与内核线程实现的区别 用户进程的数据结构，内存分布 特权级 从应用关系理解为什么有特权级别？ 平时工作的文档等是某个应用程序的应用 这个应用程序是编译器的应用 编译器是操作系统的应用 操作系统是硬件的应用 操作系统直接操作了硬件，操作系统能做什么取决于硬件提供的功能支持。操作系统最直接从操作就是CPU,CPU把CS和[E]IP指向的内容当成指令执行,把DS指向的内存当做普通数据（这是CPU规定好的，操作系统无法改变） LDT LDT（局部描述符表）；GDT(全局描述符表)，里面存放用于全局的内存描述符。描述符的功能就是描述一段内存区域的作用和属性，是对应内存区域的身份证。 LDT是任务（程序被加载到内存中，称为映像，也称为任务）的私有数据结构，每个任务都有，位置不固定。 GDT: gdt寄存器存放描述符表的起始位置，加上偏移就能访问到某个内存区域了。 LDT：lgdt寄存器存放LDT局部地址，加上偏移 TSS（任务状态段） 每个任务维持一个TSS，TSS存放任务的状态；任务切换是指就是切换不同的TSS，TSS信息存放在CPU的TR寄存器，TR寄存器指向不同的TSS,就是不同的任务切换。 TSS和其它段一样也是一片存储数据的内存区域，这段内存区域保存了任务的最新状态（也就是任务运行时占用的寄存器组等） TSS结构如下，基本上全是寄存器，TSS有CPU“维护” CPU LDT TSS TSS 和 LDT 都只能且必须在 GDT 中注册描述符，TR 寄存器中存储的是 TSS 的选择子， LDTR 寄存器中存储的是 LDT 的选择子， GDTR 寄存器中存储的是GDT 的起始地址及界限偏移 TSS 与其他普通段一样，也有自己的描述符，即TSS 描述符，用它来描述一个 TSS 的信息，此描述符需要定义在GDT中。寄存器 TR 始终指向当前任务的TSS 。任务切换就是改变 TR 的指向， CPU 自动将当前寄存器组的值（快照）写入 TR 指向的 TSS ，同时将新任务 TSS 中的各寄存器的值载入 CPU 中对应的寄存器，从而实现了任务切换。 任务切换 通过“中断＋任务门”进行任务切换 call 或 jmp＋任务门 iretd iretd 指令用于从中断处理例程中返回,两个功能 从中断返回到当前任务的中断前代码处。 当前任务是被嵌套调用时，它会调用自己 TSS 中“上一个任务的 TSS 指针”的任务，也就是返回到上一个任务 。 实现用户进程 内核中实现线程回顾 数据结构： 线程运行状态 /* 进程或线程的状态 */ enum task_status { TASK_RUNNING, TASK_READY, TASK_BLOCKED, TASK_WAITING, TASK_HANGING, TASK_DIED }; 中断栈（用于保护上下文环境） /*********** 中断栈intr_stack *********** * 此结构用于中断发生时保护程序(线程或进程)的上下文环境: * 进程或线程被外部中断或软中断打断时,会按照此结构压入上下文 * 寄存器, intr_exit中的出栈操作是此结构的逆操作 * 此栈在线程自己的内核栈中位置固定,所在页的最顶端 ********************************************/ struct intr_stack { uint32_t vec_no; // kernel.S 宏VECTOR中push %1压入的中断号 uint32_t edi; uint32_t esi; uint32_t ebp; uint32_t esp_dummy; // 虽然pushad把esp也压入,但esp是不断变化的,所以会被popad忽略 uint32_t ebx; uint32_t edx; uint32_t ecx; uint32_t eax; uint32_t gs; uint32_t fs; uint32_t es; uint32_t ds; /* 以下由cpu从低特权级进入高特权级时压入 */ uint32_t err_code; // err_code会被压入在eip之后 void (*eip) (void); uint32_t cs; uint32_t eflags; void* esp; uint32_t ss; }; 线程自己的栈 /*********** 线程栈thread_stack *********** * 线程自己的栈,用于存储线程中待执行的函数 * 此结构在线程自己的内核栈中位置不固定, * 用在switch_to时保存线程环境。 * 实际位置取决于实际运行情况。 ******************************************/ struct thread_stack { uint32_t ebp; uint32_t ebx; uint32_t edi; uint32_t esi; /* 线程第一次执行时,eip指向待调用的函数kernel_thread 其它时候,eip是指向switch_to的返回地址*/ void (*eip) (thread_func* func, void* func_arg); /***** 以下仅供第一次被调度上cpu时使用 ****/ /* 参数unused_ret只为占位置充数为返回地址 */ void (*unused_retaddr); thread_func* function; // 由Kernel_thread所调用的函数名 void* func_arg; // 由Kernel_thread所调用的函数所需的参数 }; 线程控制块：线程信息，用于调度等 /* 进程或线程的pcb,程序控制块 */ struct task_struct { uint32_t* self_kstack; // 各内核线程都用自己的内核栈 enum task_status status; char name[16]; uint8_t priority; uint8_t ticks; // 每次在处理器上执行的时间嘀嗒数 /* 此任务自上cpu运行后至今占用了多少cpu嘀嗒数, * 也就是此任务执行了多久*/ uint32_t elapsed_ticks; /* general_tag的作用是用于线程在一般的队列中的结点 */ struct list_elem general_tag; /* all_list_tag的作用是用于线程队列thread_all_list中的结点 */ struct list_elem all_list_tag; uint32_t* pgdir; // 进程自己页表的虚拟地址 uint32_t stack_magic; // 用这串数字做栈的边界标记,用于检测栈的溢出 }; 线程创建流程 // 线程PCB struct task_struct* thread = get_kernel_pages(1); void thread_create(struct task_struct* pthread, thread_func function, void* func_arg); void init_thread(struct task_struct* pthread, char* name, int prio); struct task_struct* thread_start(char* name, int prio, thread_func function, void* func_arg); 用户进程 进程与内核线程的最大区别是：进程拥有独立的4G内存虚拟地址空间，虚拟地址空间连续而物理地址空间可以不用实现，所以进程数据结构比线程数据结构至少要有一个结构来存储4G虚拟地址空间 uint32_t* pgdir; 用来保存进程页目录表的虚拟地址，这将在为进程创建页表时为其赋值 /* 进程或线程的pcb,程序控制块 */ struct task_struct { uint32_t* self_kstack; // 各内核线程都用自己的内核栈 enum task_status status; char name[16]; uint8_t priority; uint8_t ticks; // 每次在处理器上执行的时间嘀嗒数 /* 此任务自上cpu运行后至今占用了多少cpu嘀嗒数, * 也就是此任务执行了多久*/ uint32_t elapsed_ticks; /* general_tag的作用是用于线程在一般的队列中的结点 */ struct list_elem general_tag; /* all_list_tag的作用是用于线程队列thread_all_list中的结点 */ struct list_elem all_list_tag; uint32_t* pgdir; // 进程自己页表的虚拟地址 uint32_t stack_magic; // 用这串数字做栈的边界标记,用于检测栈的溢出 }; 内核线程运行在特权级0，进程绝大时间都运行在特权级3；所以进程的栈和内核线程的栈所占用的内存地址需要有不同的特权级栈空间。 特权级0 到 特权级3 一般情况下，CPU不允许从高特权级转向低特权级，除非从中断和调用们返回。 实现用户进程 利用中断，iretd指令 必须提前准备好进程的栈结构，填充好用户进程的上下文信息，再适当时候pop进程信息，恢复进程运行环境 特权级存储在栈中的CS选择子RPL中，所以当其值为3时，CPU就知道进入的特权级为3 RPL=CPL=3时，用户进程只能访问DPL为3的内存段，即代码段，数据段，栈段，所以栈中段寄存器的选择子必须指向DPL为3的内存段 对于可屏蔽中断来说，任务之所以能进入中断，是因为标志寄存器eflags中的IF位为1，退出中断还必须保持IF位为1，继续响应新的中断 用户进程特权级最低，对于IO操作，用户进程不能直接操作硬件控制，这是标志寄存器eflags中IOPL位决定的，所以实现用户进程必须使eflags的IOPL位为0 用户进程的内存空间分布 C程序内存空间分布 (1)代码段(text segment)：存放CPU执行的机器指令。通常代码段是可共享的，这使得需要频繁被执行的程序只需要在内存中拥有一份拷贝即可。代码段也通常是只读的，这样可以防止其他程序意外地修改其指令。另外，代码段还规划了局部数据所申请的内存空间信息。 代码段（code segment/text segment）通常是指用来存放程序执行代码的一块内存区域。这部分区域的大小在程序运行前就已经确定，并且内存区域通常属于只读, 某些架构也允许代码段为可写，即允许修改程序。在代码段中，也有可能包含一些只读的常数变量，例如字符串常量等。 (2)数据段(data segment)：或称全局初始化数据段/静态数据段(initialized data segment/data segment)。该段包含了在程序中明确被初始化的全局变量、静态变量(包括全局静态变量和局部静态变量)和常量数据。 (3)未初始化数据段：亦称BSS(Block Started by Symbol)。该段存入的是全局未初始化变量、静态未初始化变量。 而当程序被加载到内存单元时，则需要另外两个域：堆域和栈域。 (4)栈段(stack)：存放函数的参数值、局部变量的值，以及在进行任务切换时存放当前任务的上下文内容。 (5)堆段(heap)：用于动态内存分配，即使用malloc/free系列函数来管理的内存空间。 在将应用程序加载到内存空间执行时，操作系统负责代码段、数据段和BSS段的加载，并将在内存中为这些段分配空间。栈段亦由操作系统分配和管理，而不需要程序员显示地管理；堆段由程序员自己管理，即显示地申请和释放空间。 附：虚拟空间映射 C程序为什么进行分段？ 在保护模式下对内存的访问必须要经过段描述符，段描述符用来描述一段内存区域的访问属性，其中的S位和TYPE位可以组合成多种权限属性，处理器用这些属性来限制程序对内存的使用。 对于c程序来说，可以分为如下3个段 可读写的数据，如数据节.data和未初始化.bss 只读可执行的代码，如代码节.text和初始化代码节.init 只读数据，如只读数据节.rodata,一般情况下字符串存放在此 这将方面操作系统对程序的加载；便于安全检查 如果程序对某片内存的访问方式不符合该内存所对应的段描述符（由访问内存时使用的选择子决定）中设置的权限，比如对代码这种具备只读属性的内存区域执行了写操作，处理器会检查到这种情况井抛出GP 异常。程序必须要加载到内存中才能执行，为了符合安全检查，程序中不同属性的节必须要放置到合适的段描述符指向的内存中。 比如为程序中具有只读可执行的指令部分所分配的内存，最好是通过具有只读、可执行属性的段描述符来访问，否则若通过具有可写属性的段描述符来访问指令区域的话，程序有可能会将自己的指令部分改写，从而引起破坏。 关于用户进程的调度仍然采用了内核线程的调度方法，具体查看：https://github.com/doctording/os/tree/master/11_thread_schedule 在未实现文件系统前，kernel.bin的实现方式如下 磁盘文件 --》 载入内存 --》 解析ELF文件 --》 分配程序内存 --》 执行 main.c #include \"print.h\" #include \"init.h\" #include \"thread.h\" #include \"interrupt.h\" #include \"console.h\" #include \"process.h\" void k_thread_a(void*); void k_thread_b(void*); void u_prog_a(void); void u_prog_b(void); int test_var_a = 0, test_var_b = 0; int main(void) { put_str(\"I am kernel\\n\"); init_all(); thread_start(\"k_thread_a\", 31, k_thread_a, \"argA \"); thread_start(\"k_thread_b\", 31, k_thread_b, \"argB \"); process_execute(u_prog_a, \"user_prog_a\"); process_execute(u_prog_b, \"user_prog_b\"); intr_enable(); while(1); return 0; } /* 在线程中运行的函数 */ void k_thread_a(void* arg) { char* para = arg; while(1) { console_put_str(\" v_a:0x\"); console_put_int(test_var_a); } } /* 在线程中运行的函数 */ void k_thread_b(void* arg) { char* para = arg; while(1) { console_put_str(\" v_b:0x\"); console_put_int(test_var_b); } } /* 测试用户进程 */ void u_prog_a(void) { while(1) { test_var_a++; } } /* 测试用户进程 */ void u_prog_b(void) { while(1) { test_var_b++; } } 生成二进制的kernerl.bin 加载到了内存的0xc001500位置，通过 nm 命令查看里面的线程，进程地址 bochs直接运行后，进程a,b正常运行，可以看到变量test_var_b不断的+ bochs运行后 lb 0xc00015df 使程序暂停在进程a的位置 cs:0x002b 特权级有3 种：CPL,DPL 和RPL，每个都是有4个等级（0,1,2,3）。 一般来说，CPL 代表当前代码段的权限，如果它想要去访问一个段或门，首先要看看对方的权限如何，也就是检查对方的DPL，如果满足当前的权限比要访问的权限高，则有可能允许去访问，有些情况我们还要检查选择子的权限，即RPL,因为我们通过选择子:偏移量的方式去访问一个段，这算是一个访问请求动作，因此称为请求访问权限RPL(Requst Privilege Level)。当请求权限也满足条件，那么访问就被允许了。 RPL 是通过选择子的低两位来表现出来的(这么说来，CS 和SS 也是存放选择子的，同时CPL存放在CS 和SS 的低两位上，那么对CS 和SS 来说，选择子的RPL=当前段的CPL)。处理器通过检查RPL 和CPL 来确认一个访问是否合法。 cs：0x002b (0000 0000 0010 1011) 最后两位是数字3，代表特权级是3，是用户进程。 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-09-05 17:29:25 "},"content/16_system_call/":{"url":"content/16_system_call/","title":"16 系统调用实现用户进程","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 系统调用 用户进程pid实现 系统调用内存管理 arena数据结构（将一大块内存划分成多个小内存块，每个小内存块之间互不干涉） 实现：sysmalloc, sysfree, malloc, free 系统调用 系统调用由操作系统核心提供，运行于核心态，而普通的函数调用由函数库或用户自己提供，运行于用户态 系统调用在用户空间进程和硬件设备之间添加了一个中间层 它为用户空间提供了一种统一的硬件的抽象接口 系统调用保证了系统的稳定和安全。作为硬件设备和应用程序之间的中间人，内核可以基于权限和其他一些规则对需要进行的访问进行裁决。举例来说，这样可以避免应用程序不正确地使用硬件设备，窃取其他进程的资源，或做出其他什么危害系统的事情。 在Linux中，系统调用是用户空间访问内核的惟一手段；除异常和中断外，它们是内核惟一的合法入口。 用户空间的程序无法直接执行内核代码。如果果进程可以直接在内核的地址空间上读写的话，系统安全就会失去控制。所以，应用程序应该以某种方式通知系统，告诉内核自己需要执行一个系统调用，希望系统切换到内核态，这样内核就可以代表应用程序来执行该系统调用了。通知内核的机制是靠软件中断实现的。 参考博文：http://blog.csdn.net/zhuxiaoping54532/article/details/51700576 用户进程pid实现 进程结构体重新增pid成员变量 pid采用静态全局变量，锁控制+1,确保唯一 进程初始化是就分配好pid 为进程添加系统调用getpid系统调用接口 代码见16_system\\code\\pro_getpid 主函数 int main(void) { put_str(\"I am kernel\\n\"); init_all(); process_execute(u_prog_a, \"user_prog_a\"); process_execute(u_prog_b, \"user_prog_b\"); intr_enable(); console_put_str(\" main_pid:0x\"); console_put_int(sys_getpid()); console_put_char('\\n'); thread_start(\"k_thread_a\", 31, k_thread_a, \"argA \"); thread_start(\"k_thread_b\", 31, k_thread_b, \"argB \"); while(1); return 0; } /* 在线程中运行的函数 */ void k_thread_a(void* arg) { char* para = arg; console_put_str(\" thread_a_pid:0x\"); console_put_int(sys_getpid()); console_put_char('\\n'); console_put_str(\" prog_a_pid:0x\"); console_put_int(prog_a_pid); console_put_char('\\n'); while(1); } /* 在线程中运行的函数 */ void k_thread_b(void* arg) { char* para = arg; console_put_str(\" thread_b_pid:0x\"); console_put_int(sys_getpid()); console_put_char('\\n'); console_put_str(\" prog_b_pid:0x\"); console_put_int(prog_b_pid); console_put_char('\\n'); while(1); } /* 测试用户进程 */ void u_prog_a(void) { prog_a_pid = getpid(); while(1); } /* 测试用户进程 */ void u_prog_b(void) { prog_b_pid = getpid(); while(1); } 运行截图 系统调用内存管理 arena数据结构（将一大块内存划分成多个小内存块，每个小内存块之间互不干涉） 元信息： 描述自己内存池中的空闲内存块数量，包括内存块描述符指针 大小估计，约为12字节 粒度较小的内存小块（mem_block） 用于内存分配 一个arena提供的内存空间大小是有限的，当一个arena用完了，就需要一个新的arena(arena集群) 同一类内存块可以用多个arena提供，每一个类内存块可以建立聂村块描述符（块大小，arena链表) /* 内存块 */ struct mem_block { struct list_elem free_elem; }; /* 内存块描述符 */ struct mem_block_desc { uint32_t block_size; // 内存块大小 uint32_t blocks_per_arena; // 本arena中可容纳此mem_block的数量. struct list free_list; // 目前可用的mem_block链表 }; /* 内存仓库arena元信息 */ struct arena { struct mem_block_desc* desc; // 此arena关联的mem_block_desc /* large为ture时,cnt表示的是页框数。 * 否则cnt表示空闲mem_block数量 */ uint32_t cnt; bool large; }; 实现：sys_malloc, sys_free, malloc, free 代码见 16_system\\code\\pro_malloc_free void k_thread_a(void*); void k_thread_b(void*); void u_prog_a(void); void u_prog_b(void); int main(void) { put_str(\"I am kernel\\n\"); init_all(); intr_enable(); process_execute(u_prog_a, \"u_prog_a\"); process_execute(u_prog_b, \"u_prog_b\"); thread_start(\"k_thread_a\", 31, k_thread_a, \"I am thread_a\"); thread_start(\"k_thread_b\", 31, k_thread_b, \"I am thread_b\"); while(1); return 0; } /* 在线程中运行的函数 */ void k_thread_a(void* arg) { void* addr1 = sys_malloc(256); void* addr2 = sys_malloc(255); void* addr3 = sys_malloc(254); console_put_str(\" thread_a malloc addr:0x\"); console_put_int((int)addr1); console_put_char(','); console_put_int((int)addr2); console_put_char(','); console_put_int((int)addr3); console_put_char('\\n'); int cpu_delay = 100000; while(cpu_delay-- > 0); sys_free(addr1); sys_free(addr2); sys_free(addr3); while(1); } /* 在线程中运行的函数 */ void k_thread_b(void* arg) { void* addr1 = sys_malloc(256); void* addr2 = sys_malloc(255); void* addr3 = sys_malloc(254); console_put_str(\" thread_b malloc addr:0x\"); console_put_int((int)addr1); console_put_char(','); console_put_int((int)addr2); console_put_char(','); console_put_int((int)addr3); console_put_char('\\n'); int cpu_delay = 100000; while(cpu_delay-- > 0); sys_free(addr1); sys_free(addr2); sys_free(addr3); while(1); } /* 测试用户进程 */ void u_prog_a(void) { void* addr1 = malloc(256); void* addr2 = malloc(255); void* addr3 = malloc(254); printf(\" prog_a malloc addr:0x%x,0x%x,0x%x\\n\", (int)addr1, (int)addr2, (int)addr3); int cpu_delay = 100000; while(cpu_delay-- > 0); free(addr1); free(addr2); free(addr3); while(1); } /* 测试用户进程 */ void u_prog_b(void) { void* addr1 = malloc(256); void* addr2 = malloc(255); void* addr3 = malloc(254); printf(\" prog_b malloc addr:0x%x,0x%x,0x%x\\n\", (int)addr1, (int)addr2, (int)addr3); int cpu_delay = 100000; while(cpu_delay-- > 0); free(addr1); free(addr2); free(addr3); while(1); } Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-02 17:41:35 "},"content/17_hd_driver/":{"url":"content/17_hd_driver/","title":"17 硬件驱动认识","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 硬件驱动 bochs的bximage命令创建硬盘，BIOS识别 在bochs的配置文件中添加从盘hd80M.img 磁盘相关概念回顾 磁盘分区概念 fdisk 分区实践 编写硬盘驱动程序 硬件驱动 bochs的bximage命令创建硬盘，BIOS识别 创建出的硬盘有格式，并且详细信息可以看到 柱面数 cyl=162 磁头数 heads=16 每磁道扇区数 sectors per track=63 总共的扇区数 total sectors=163296 总共大小 total size=79.73 megabytes 在bochs的配置文件中添加从盘hd80M.img ata0-master: type=disk, mode=flat, path=\"/home/john/os/hd30M.img\", cylinders=60, heads=16, spt=63 ata0-slave: type=disk, mode=flat, path=\"/home/john/os/hd80M.img\", cylinders=162, heads=16, spt=63 在物理地址Ox475处存储着主机上安装的硬盘的数量，它是由 BIOS 检测并写入的， bochs运行后，ctrl+c中断，然后使用xp命令查看 只有一个主磁盘 添加hd80M.img的从盘 磁盘相关概念回顾 硬盘容量＝单片容量×磁头数。 单片容量＝每磁道扇区数×磁道数目×一个扇区大小。 扇区大小一般是512字节，扇区是硬盘读写的基本单位 磁盘读写很慢，因此操作系统不可能一次只写一个扇区，为了优化 1/0，操作系统把数据积攒到“多个扇区”时再一次性写入磁盘，这里的“多个扇区”就是指操作系统的簇或块。通常标准库函数还进行了二次优化，数据可以积攒到多个族或块时才写入，不过标准库中还提供了控制选项，可以立即把数据刷进硬盘。 以hd80M.img为例 * 柱面数 cyl=162 * 磁头数 heads=16 * 每磁道扇区数 sectors per track=63 * 总共的扇区数 total sectors=163296 * 总共大小 total size=79.73 megabytes 16（磁头数） 162 （每个磁头的磁道数） 63（m每个磁道的扇区数）* 512 （每个扇区的大小）= 83607552B 即 79.73MB 磁盘分区概念 熟悉的磁盘分区格式: MBR, GPT 分区：人为地将硬盘上的柱面扇区划分成不同的分组，每个分组都是单独的分区。各分区都有“描述符”来描述分区本身所在硬盘上的起止界限等信息. MBR分区中有个 64 字节“固定大小”的数据结构，这就是著名的分区表，分区表中的每个表项就是一个分区的“描述符”，表项大小是 16 字节，因此 64 字节的分区表总共可容纳 4 个表项，这就是为什么MBR分区格式的硬盘仅支持 4 个分区的原因。 MBR (MainBootR四ord ）即主引导记录，它是一段引导程序，其所在的扇区称为主引导扇区，该扇区位于 0 盘。道 1 扇区（物理扇区编号从 1 开始，逻辑扇区地址 LBA 从 0 开始），也就是硬盘最开始的扇区，扇区大小为 512 宇节，这 512 字节内容由三部分组成。 主引导记录 MBR 磁盘分区表 DPT 结束魔数 55AA ，表示此扇区为主引导扇区，里面包含控制程序 MBR引导程序位于主引导扇区中偏移 0～OxlBD 的空间，共计 446 字节大小，这其中包括硬盘参数及部分指令（由 BIOS 跳入执行），它是由分区工具产生的，独立于任何操作系统。 OxlBD-OxlFD 64字节就是磁盘分区表 DPT 磁盘分区表（ Disk Partition Table ）简称 DPT，是由多个分区元信息汇成的表，表中每一个表项都对 应一个分区，主要记录各分区的起始扇区地址，大小界限等 。16字节内容如下 魔数 55AA 作为主引导扇区的有效标志，位于扇区偏移 OxlFE～OxI FF，也就是最后 2 个字节。 分区表共4个分区，那个分区作为扩展分区都可以，扩展分区是可选的，最多只能有一个；其余的都是主分区。扩展分区中的第一个逻辑分区的编号从5开始。 分区可以继续分成小的子分区,这就是逻辑分区，逻辑分区只存在扩展分区，他属于扩展分区的子集。 fdisk 分区实践 hd80M.img 空盘查看 设置磁盘的柱面数，磁头数 添加分区 根据扩展分区创建逻辑分区 保存分区信息 查看已知的文件系统id 设置分区的文件系统id 最后的磁盘信息如下 #usage: sh xxd.sh 文件 起始地址 长度 xxd -u -a -g 1 -s $2 -l $3 $1 16字节信息规定 第一个主分区 00 00 21 02 83 （文件系统id） 03 34 65 00 08 00 00 （ 分区起始偏移扇区 0x00000800） A1 86 01 00 ( 扇区总数 0x000186A1) 扩展分区 00 03 35 65 05 （文件系统id） 0F 3F A1 A1 8E 01 00 （ 分区起始偏移扇区 0x00018EA1 ） 3F EF 00 00 ( 扇区总数 0x0000EF3F ) 查看扩展分区0x00018EA1*512 = 0x031D4200 sh xxd.sh hd80M.img 0x031D4200 512 扩展分区的第一个逻辑分区 00 04 16 67 66 00 31 77 00 08 00 00 （ 分区起始偏移扇区 0x00000800,这个是相对扩展分区的，真正对整个磁盘的偏移扇区是 0x00018EA1 + 0x00000800 = 0x000196A1） 20 3E 00 00 ( 扇区总数 0x00003E20 ) 编写硬盘驱动程序 硬件是个独立的个体，它提供一套方法作为操作接口给外界调用，但此接口往往是最原始、最简陋、最繁琐的，相对咱们习惯的高级语言来说，这些接口使用起来非常麻烦，很多指令要提前设置好各种参数，基本上都是要用汇编语言来操作寄存器。 硬件是实实在在的东西，要想在软件中管理它们，只能从逻辑上抓住这些硬件的特性，将它们抽象成一些数据结构，然后这些数据结构便代表了硬件，用这些数据结构来组织硬件的信息及状态，在逻辑上硬件就是这数据结构。 驱动程序： 对硬件接口的封装，它把参数设置等重复、枯燥、复杂的过程封装成一个过程，避免每次执行命令时都重复做这些工作，根据需要也可以提供相关的策略，如缓存等，让硬件操作更加容易、省事、方便，无需再显式做一些底层设置。 没有驱动程序的话，操作系统也是可以同硬件交流的，无非是直接操作 IO 端口 硬盘基础回顾 硬盘当成一个IO设备，其有硬盘控制器（I/O接口）,就像显示器一样，其有显卡（也称为显示适配器），显存。 针对IDE硬盘，对其进行抽象 /* 硬盘结构 */ struct disk { char name[8]; // 本硬盘的名称，如sda等 struct ide_channel* my_channel; // 此块硬盘归属于哪个ide通道 uint8_t dev_no; // 本硬盘是主0还是从1 struct partition prim_parts[4]; // 主分区顶多是4个 struct partition logic_parts[8]; // 逻辑分区数量无限,但总得有个支持的上限,那就支持8个 }; /* ata通道结构 */ struct ide_channel { char name[8]; // 本ata通道名称, 如ata0,也被叫做ide0. 可以参考bochs配置文件中关于硬盘的配置。 uint16_t port_base; // 本通道的起始端口号 uint8_t irq_no; // 本通道所用的中断号 struct lock lock; bool expecting_intr; // 向硬盘发完命令后等待来自硬盘的中断 struct semaphore disk_done; // 硬盘处理完成.线程用这个信号量来阻塞自己，由硬盘完成后产生的中断将线程唤醒 struct disk devices[2]; // 一个通道上连接两个硬盘，一主一从 }; 硬盘分区结构也进行抽象 /* 分区结构 */ struct partition { uint32_t start_lba; // 起始扇区 uint32_t sec_cnt; // 扇区数 struct disk* my_disk; // 分区所属的硬盘 struct list_elem part_tag; // 用于队列中的标记 char name[8]; // 分区名称 struct super_block* sb; // 本分区的超级块 struct bitmap block_bitmap; // 块位图 struct bitmap inode_bitmap; // i结点位图 struct list open_inodes; // 本分区打开的i结点队列 }; /* 构建一个16字节大小的结构体,用来存分区表项 */ struct partition_table_entry { uint8_t bootable; // 是否可引导 uint8_t start_head; // 起始磁头号 uint8_t start_sec; // 起始扇区号 uint8_t start_chs; // 起始柱面号 uint8_t fs_type; // 分区类型 uint8_t end_head; // 结束磁头号 uint8_t end_sec; // 结束扇区号 uint8_t end_chs; // 结束柱面号 /* 更需要关注的是下面这两项 */ uint32_t start_lba; // 本分区起始扇区的lba地址 uint32_t sec_cnt; // 本分区的扇区数目 } __attribute__ ((packed)); // 保证此结构是16字节大小 /* 引导扇区,mbr或ebr所在的扇区 */ struct boot_sector { uint8_t other[446]; // 引导代码 struct partition_table_entry partition_table[4]; // 分区表中有4项,共64字节 uint16_t signature; // 启动扇区的结束标志是0x55,0xaa, } __attribute__ ((packed)); 硬盘和 CPU 是相互独立的个体，它们各自并行执行，但由于硬盘是低速设备，其在处理请求时往往消耗很长的时间,为避免浪费 CPU 资源，在等待硬盘操作的过程中最好把 CPU 主动让出来，让 CPU 去执行其他任务 /* 将buf中sec_cnt扇区数据写入硬盘 */ void ide_write(struct disk* hd, uint32_t lba, void* buf, uint32_t sec_cnt) { ASSERT(lba 0); lock_acquire (&hd->my_channel->lock); /* 1 先选择操作的硬盘 */ select_disk(hd); uint32_t secs_op; // 每次操作的扇区数 uint32_t secs_done = 0; // 已完成的扇区数 while(secs_done my_channel, CMD_WRITE_SECTOR); // 准备开始写数据 /* 4 检测硬盘状态是否可读 */ if (!busy_wait(hd)) { // 若失败 char error[64]; sprintf(error, \"%s write sector %d failed!!!!!!\\n\", hd->name, lba); PANIC(error); } /* 5 将数据写入硬盘 */ write2sector(hd, (void*)((uint32_t)buf + secs_done * 512), secs_op); /* 在硬盘响应期间阻塞自己 */ sema_down(&hd->my_channel->disk_done); secs_done += secs_op; } /* 醒来后开始释放锁*/ lock_release(&hd->my_channel->lock); } thread_yield 定义在也read.c 中，它的功能是主动把 CPU 使用权让出来，它与出thread_block 的区别是thread_yield 执行后任务的状态是 TASK_READY，即让出 CPU 后，它会被加入到就绪队列中，下次还能继续被调度器调度执行，而 thread_block 执行后任务的状态是 TASK_BLOCKED，需要被唤醒后才能加入到就绪队列 ， 所以下次执行还不知道是什么时候 。 /* 硬盘数据结构初始化 */ void ide_init() { printk(\"ide_init start\\n\"); uint8_t hd_cnt = *((uint8_t*)(0x475)); // 获取硬盘的数量 ASSERT(hd_cnt > 0); list_init(&partition_list); channel_cnt = DIV_ROUND_UP(hd_cnt, 2); // 一个ide通道上有两个硬盘,根据硬盘数量反推有几个ide通道 struct ide_channel* channel; uint8_t channel_no = 0, dev_no = 0; /* 处理每个通道上的硬盘 */ while (channel_no name, \"ide%d\", channel_no); /* 为每个ide通道初始化端口基址及中断向量 */ switch (channel_no) { case 0: channel->port_base = 0x1f0; // ide0通道的起始端口号是0x1f0 channel->irq_no = 0x20 + 14; // 从片8259a上倒数第二的中断引脚,温盘,也就是ide0通道的的中断向量号 break; case 1: channel->port_base = 0x170; // ide1通道的起始端口号是0x170 channel->irq_no = 0x20 + 15; // 从8259A上的最后一个中断引脚,我们用来响应ide1通道上的硬盘中断 break; } channel->expecting_intr = false; // 未向硬盘写入指令时不期待硬盘的中断 lock_init(&channel->lock); /* 初始化为0,目的是向硬盘控制器请求数据后,硬盘驱动sema_down此信号量会阻塞线程, 直到硬盘完成后通过发中断,由中断处理程序将此信号量sema_up,唤醒线程. */ sema_init(&channel->disk_done, 0); register_handler(channel->irq_no, intr_hd_handler); /* 分别获取两个硬盘的参数及分区信息 */ while (dev_no devices[dev_no]; hd->my_channel = channel; hd->dev_no = dev_no; sprintf(hd->name, \"sd%c\", 'a' + channel_no * 2 + dev_no); identify_disk(hd); // 获取硬盘参数 if (dev_no != 0) { // 内核本身的裸硬盘(hd60M.img)不处理 partition_scan(hd, 0); // 扫描该硬盘上的分区 } p_no = 0, l_no = 0; dev_no++; } dev_no = 0; // 将硬盘驱动器号置0,为下一个channel的两个硬盘初始化。 channel_no++; // 下一个channel } printk(\"\\n all partition info\\n\"); /* 打印所有分区信息 */ list_traversal(&partition_list, partition_info, (int)NULL); printk(\"ide_init done\\n\"); } 运行截图 对比磁盘hd80M.img的信息，对比结果 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-02 17:46:20 "},"content/18_filesystem/":{"url":"content/18_filesystem/","title":"18 硬盘到文件系统","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 文件系统的实现 磁盘空间分配 连续分配 主要优点 主要缺点 链接分配 主要优点 主要缺点 索引分配 主要优点 主要缺点 目录，超级块 超级块是保存文件系统元信息的元信息 创建文件系统 运行程序和测试 文件系统的实现 磁盘空间分配 硬盘是低速设备，其读写单位是扇区，为了避免频繁访问硬盘，操作系统不会有了一扇区数据就去读写一次磁盘，往往等数据积攒到“足够大小”时才一次性访问硬盘，这足够大小的数据就是块，一个块是由多个扇区组成的，块大小是扇区大小的整数倍。 块是文件系统的读写单位，因此文件至少要占据一个块，当文件体积大于 l 个块时，文件肯定被拆分成多个块来存储,多个块如何组织到一起--》磁盘空间分配方法 连续分配 连续分配要求每个文件在磁盘上占有一组连续的块。（块与块必需紧挨着） 主要优点 可以直接访问文件 因为数据集中存放在连续的盘块中，访问时所需的寻道次数和寻道时间少。 主要缺点 由于插入和删除记录会引起其它记录的移动，在外存中执行此操作会引起磁头的频繁来回移动，因此连续结构只能在文件的末尾插入记录，删除记录时，只作标记进行逻辑删除，只有用户指定物理删除时才真正删除相应记录，进行记录的移动； 顺序文件需要连续的盘块存放数据，因此，在插入记录时如果原来分配的盘块已没有空闲空间，而与其邻接的盘块也不空闲时，需要重新在外存中查找新的较大的空闲空间，并将原有数据移动到新空间中，然后才能插入新的数据，因此，连续结构不易动态增长，而且外存容易存在碎片。 链接分配 （类似链表，块与块位置任意的，每个块有个链接指针） 主要优点 提高了磁盘空间利用率，解决了磁盘碎片问题； 便于文件的插入和删除操作； 便于文件的动态增长。 主要缺点 只能有效的用于文件的顺序访问而不能有效的支持文件的直接访问。要找到文件的第i块，必须从文件的开始起，跟着指针，找到第i块。对指针的每次访问都需要读磁盘。 指针需要空间。每个文件需要比原来更多的空间。 可靠性问题，文件由指针链接的，指针分布于整个磁盘，如果指针丢失或损坏，可能导致链接空闲空间或另一个文件。 索引分配 （索引表，把链接分配的指针放到一起，形成一个索引地址数组） 链接分配解决了连续分配的外部碎片和大小声明问题，但是如果不用FAT，那么链接分配不能有效的支持直接访问。索引分配把所有指针放在一起，即通过索引块解决了这个问题。 对于大文件 多层索引 组合方案，结合链接索引 多层索引 主要优点 支持直接访问 解决了磁盘碎片问题 文件修改方便：主要是对索引表的操作 主要缺点 索引表占用了磁盘空间 目录，超级块 linux inode结构？ 目录也是文件，也有inode； 目录是包含文件的文件，目录记录了其下的所有文件==》目录项 类似树结构，最开始的目录是 分区的“根目录 /” 例： 有了目录项后，通过文件名找文件实体数据块的流程 1 在目录中找到文件名所在的目录项 。 2 从目录项中获取 inode 编号 。 3 用 inode 编号作为 inode 数组的索引下标，找到 inode 4 从该 inode 中获取数据块的地址，读取数据块 。 超级块是保存文件系统元信息的元信息 超级块是文件系统元信息的“配置文件”，它是在为分区创建文件系统时创建的，所有有关文件系统元信息的配置都在超级块中，因此超级块的位置和大小不能再被“配置”了，必须是固定的，它被固定存储在各分区的第 2 个扇区，通常是占用一个扇区的大小，具体大小与实际文件系统类型为准。 例如一个 常见的磁盘文件系统布局 魔数用来确定文件系统的类型的标志，用它来区别于其他文件系统。 根目录和空闲块区域是真正用于存储数据的区域，除了这两部分，其他几个部分占用的扇区数取决于分区的容量大小，或者是在创建文件系统的过程中手动设置 。 创建文件系统 仍然是用数据结构抽象 超级块，inode,目录项等 数据块大小可以设定为1个扇区 /* 超级块 */ struct super_block { uint32_t magic; // 用来标识文件系统类型,支持多文件系统的操作系统通过此标志来识别文件系统类型 uint32_t sec_cnt; // 本分区总共的扇区数 uint32_t inode_cnt; // 本分区中inode数量 uint32_t part_lba_base; // 本分区的起始lba地址 uint32_t block_bitmap_lba; // 块位图本身起始扇区地址 uint32_t block_bitmap_sects; // 扇区位图本身占用的扇区数量 uint32_t inode_bitmap_lba; // i结点位图起始扇区lba地址 uint32_t inode_bitmap_sects; // i结点位图占用的扇区数量 uint32_t inode_table_lba; // i结点表起始扇区lba地址 uint32_t inode_table_sects; // i结点表占用的扇区数量 uint32_t data_start_lba; // 数据区开始的第一个扇区号 uint32_t root_inode_no; // 根目录所在的I结点号 uint32_t dir_entry_size; // 目录项大小 uint8_t pad[460]; // 加上460字节,凑够512字节1扇区大小 } __attribute__ ((packed)); /* inode结构 */ struct inode { uint32_t i_no; // inode编号 /* 当此inode是文件时,i_size是指文件大小, 若此inode是目录,i_size是指该目录下所有目录项大小之和*/ uint32_t i_size; uint32_t i_open_cnts; // 记录此文件被打开的次数 bool write_deny; // 写文件不能并行,进程写文件前检查此标识 /* i_sectors[0-11]是直接块, i_sectors[12]用来存储一级间接块指针 */ uint32_t i_sectors[13]; struct list_elem inode_tag; }; #define MAX_FILE_NAME_LEN 16 // 最大文件名长度 /* 目录结构 */ struct dir { struct inode* inode; uint32_t dir_pos; // 记录在目录内的偏移 uint8_t dir_buf[512]; // 目录的数据缓存 }; /* 目录项结构 */ struct dir_entry { char filename[MAX_FILE_NAME_LEN]; // 普通文件或目录名称 uint32_t i_no; // 普通文件或目录对应的inode编号 enum file_types f_type; // 文件类型 }; 创建文件系统就是创建文件系统所需要的元信息，这包括超级块位置及大小、 空闲块位图的位置及大小 、inode 位图的位置及大小 、 inode 数组的位置及大小、 空闲块起始地址、 根目录起始地址 。创建步骤如下： 1 根据分区 part 大小， 计算分区文件系统各元信息需要的扇区数及位置 。 2 在 内 存中 创建超级块，将以上步骤计算的元信息写入超级块。 3 将超级块写入磁盘。 4 将元信息写入磁盘上各自的位置。 5 将根目录写入磁盘 挂载分区 文件系统的主要工作是资源管理，跟踪资源的状态是通过位图来实现的，因此创建文件系统就是创建各种资源的位图，位图肯定是在内存中先创建好，然后再将位图持久化到硬盘，＂持久化”是指把数据写到可以长久保存信息的存储介质上，永远保存，比如磁盘就是一种持久化存储介质。 挂载分区前内存中可没有位图，这就需要事先把这些位图提前持久化到磁盘上，挂载分区时再把位图从硬盘上加载到内存。由于内存不能长久保存数据，断电之后内存中的一切都会灰飞烟灭，所以即使是将来挂载分区后，内存中的位图哪怕只是更改了一个位，都要及时同步持久化到磁盘上。 /* 在磁盘上搜索文件系统,若没有则格式化分区创建文件系统 */ void filesys_init() { uint8_t channel_no = 0, dev_no, part_idx = 0; /* sb_buf用来存储从硬盘上读入的超级块 */ struct super_block* sb_buf = (struct super_block*)sys_malloc(SECTOR_SIZE); if (sb_buf == NULL) { PANIC(\"alloc memory failed!\"); } printk(\"searching filesystem......\\n\"); while (channel_no prim_parts; while(part_idx logic_parts; } /* channels数组是全局变量,默认值为0,disk属于其嵌套结构, * partition又为disk的嵌套结构,因此partition中的成员默认也为0. * 若partition未初始化,则partition中的成员仍为0. * 下面处理存在的分区. */ if (part->sec_cnt != 0) { // 如果分区存在 memset(sb_buf, 0, SECTOR_SIZE); /* 读出分区的超级块,根据魔数是否正确来判断是否存在文件系统 */ ide_read(hd, part->start_lba + 1, sb_buf, 1); /* 只支持自己的文件系统.若磁盘上已经有文件系统就不再格式化了 */ if (sb_buf->magic == 0x19590318) { printk(\"%s has filesystem\\n\", part->name); } else { // 其它文件系统不支持,一律按无文件系统处理 printk(\"formatting %s`s partition %s......\\n\", hd->name, part->name); partition_format(part); } } part_idx++; part++; // 下一分区 } dev_no++; // 下一磁盘 } channel_no++; // 下一通道 } sys_free(sb_buf); } 遍历磁盘，然后遍历磁盘上的分区，判断分区是否有文件系统，否则格式化成自己设定的文件系统。 运行程序和测试 第一次运行会格式化磁盘，创建超级块，inode等 第二次运行时，由于第一次分区已经格式化有文件系统了，则会显示分区已有文件系统的信息 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-02 17:49:06 "},"content/19_fd_inode_dir_file/":{"url":"content/19_fd_inode_dir_file/","title":"19 文件描述符操作","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 文件描述符 文件描述符 文件描述符与inode 文件 相关操作 创建普通文件需要考虑的工作 创建目录 文件和目录的创建，读写 目录的打开关闭 文件和目录的删除 文件描述符 inode相关操作（目录，路径解析，文件检索） 文件描述符 内核（kernel）利用文件描述符（file descriptor）来访问文件。文件描述符是非负整数。打开现存文件或新建文件时，内核会返回一个文件描述符。读写文件也需要使用文件描述符来指定待读写的文件。该扇区，从而实现了文件的读写。几乎所有的操作系统都允许一个进程同时、多次、打开同一个文件（并不关闭），同样该文件也可以被多个不同的进程同时打开。 为实现文件任意位置的读写，执行读写操作时可以指定偏移量作为该文件内的起始地址，此偏移量相当于文件内的指针。 文件描述符与inode 读写文件的本质是 先通过文件的 inode 找到文件数据块的扇区地址，随后读写。 可以组织一个\"文件数据结构\"（包含文件偏移量，文件打开标志，inode指针等信息），方便对文件进行操作，即文件描述符。 在linux中每个进程都有单独的，完全相同的一套文件描述符，因此它们与其他进程的文件描述符互不干涉，这些文件描述符被组织成文件描述符数组进行统一的管理。 （每个进程在PCB（Process Control Block）中保存着一份文件描述符表，文件描述符就是这个表的索引，每个表项都有一个指向已打开文件的指针。） Linux 通过文件描述符查找文件数据块 进程PCB中有文件描述符数组 文件表中存储了所有文件的结构（文件结构中有inode先关信息） -- 在内存中创建好的全局结构 根据inode队列（inode缓存），找到最终的磁盘位置 文件 相关操作 创建普通文件 file_create 函数 创建普通文件需要考虑的工作 1) 文件需要 inode 来描述大小、位置等属性 ，所以创建文件就要创建其 inode 。这就涉及到向inode_bitmap 申请位图来获得 inode 号，因此 inode_bitmap 会被更新， inode_table 数组中的某项也会由新的 inode 填充 。 2) inode->i_sectors 是文件具体存储的扇区地址，这需要向 block_bitmap 申请可用位来获得可用的块（在我们这里，为简化处理， 1 块等于 1 扇区），因此 block_bitmap 会被更新，分区的数据区 data_start_lba 以后的某个扇区会被分配 。 3) 新增加的文件必然存在于某个目录，所以该目录的 inode->i_size 会增加一个目录项的大小(目录项存储文件名和i节点) 。 此新增加的文件对应的目录项需要写入该目录的 inode->i_sectors［］中的某个扇区，原有扇区可能己满，所以有可能要申请新扇区来存储目录项 。 4) 若其中某步操作失败，需要回滚到之前己成功的操作。 5) inode_bitmap 、 block_bitmap、新文件的 inode 及文件所在目录的 inode，这些位于内存中已经被改变的数据要同步到硬盘。 创建目录 创建目录所涉及的工作包括。 1) 确认待创建的新目录在文件系统上不存在。 2) 为新目录创建 inode 。 3) 为新目录分配 1 个块存储该目录中的目录项。 4) 在新目录中创建两个目录项\".\"和\"..\",这是每个目录都必须存在的两个目录项。 5) 在新目录的父目录中添加新目录的目录项。 6) 将以上资源的变更同步到硬盘。 遍历目录就是读取目录中所有的目录项，在遍历之前必须要先把目录打开，之后还需要把目录关闭。 pwd命令和cd命令： 每个目录都存储着当前目录和上一级目录，所以可以理论上可以访问到分区中所有的目录 文件和目录的创建，读写 代码见19_fd_inode_dir_file\\code\\code_01 printf(\"/dir1/subdir1 create %s!\\n\", sys_mkdir(\"/dir1/subdir1\") == 0 ? \"done\" : \"fail\"); printf(\"/dir1 create %s!\\n\", sys_mkdir(\"/dir1\") == 0 ? \"done\" : \"fail\"); printf(\"now, /dir1/subdir1 create %s!\\n\", sys_mkdir(\"/dir1/subdir1\") == 0 ? \"done\" : \"fail\"); int fd = sys_open(\"/dir1/subdir1/file2\", O_CREAT|O_RDWR); if (fd != -1) { printf(\"/dir1/subdir1/file2 create done!\\n\"); sys_write(fd, \"Catch me if you can!\\n\", 21); sys_lseek(fd, 0, SEEK_SET); char buf[32] = {0}; sys_read(fd, buf, 21); printf(\"/dir1/subdir1/file2 says:\\n%s\", buf); sys_close(fd); } 目录的打开关闭 在文件，目录创建成功，并写入磁盘的基础上，测试目录的打开与关闭 struct dir* p_dir = sys_opendir(\"/dir1/subdir1\"); if (p_dir) { printf(\"/dir1/subdir1 open done!\\n\"); if (sys_closedir(p_dir) == 0) { printf(\"/dir1/subdir1 close done!\\n\"); } else { printf(\"/dir1/subdir1 close fail!\\n\"); } } else { printf(\"/dir1/subdir1 open fail!\\n\"); } 文件和目录的删除 /******** 测试代码 ********/ printf(\"/dir1 content before delete /dir1/subdir1:\\n\"); struct dir* dir = sys_opendir(\"/dir1/\"); char* type = NULL; struct dir_entry* dir_e = NULL; while((dir_e = sys_readdir(dir))) { if (dir_e->f_type == FT_REGULAR) { type = \"regular\"; } else { type = \"directory\"; } printf(\" %s %s\\n\", type, dir_e->filename); } printf(\"try to delete nonempty directory /dir1/subdir1\\n\"); if (sys_rmdir(\"/dir1/subdir1\") == -1) { printf(\"sys_rmdir: /dir1/subdir1 delete fail!\\n\"); } printf(\"try to delete /dir1/subdir1/file2\\n\"); if (sys_rmdir(\"/dir1/subdir1/file2\") == -1) { printf(\"sys_rmdir: /dir1/subdir1/file2 delete fail!\\n\"); } if (sys_unlink(\"/dir1/subdir1/file2\") == 0 ) { printf(\"sys_unlink: /dir1/subdir1/file2 delete done\\n\"); } printf(\"try to delete directory /dir1/subdir1 again\\n\"); if (sys_rmdir(\"/dir1/subdir1\") == 0) { printf(\"/dir1/subdir1 delete done!\\n\"); } printf(\"/dir1 content after delete /dir1/subdir1:\\n\"); sys_rewinddir(dir); while((dir_e = sys_readdir(dir))) { if (dir_e->f_type == FT_REGULAR) { type = \"regular\"; } else { type = \"directory\"; } printf(\" %s %s\\n\", type, dir_e->filename); } /******** 测试代码 ********/ Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-02 17:51:03 "},"content/20_shell/":{"url":"content/20_shell/","title":"20 shell简单实现","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 实现简单shell fork函数复习 实现read系统调用,putchar(输出一个字符), clear(清屏） 简单的shel -- 获取键盘输入 简单的shel -- 解析键盘输入 shell实现ls, cd ,mkdir，pwd等命令 运行截图 实现简单shell fork函数复习 fork用老进程克隆出一个新进程并使新进程执行：fork先复制进程资源，然后跳过去执行 fork复制的内容： 进程PCB，即task_struct 一般PCB包括如下： （1）进程标识符（内部，外部） （2）处理机的信息（通用寄存器，指令计数器，PSW，用户的栈指针）。 （3）进程调度信息（进程状态，进程的优先级，进程调度所需的其它信息，事件） （4）进程控制信息（程序的数据的地址，资源清单，进程同步和通信机制，链接指针） 程序体，即代码段，数据段等，这是进程的实体 用户栈，编译器会把局部变量在栈中创建，并且函数调用也需要栈 内核栈，进入内核态时，一方面用来保存上下文环境，另一方面同用户栈 虚拟地址池，每个进程拥有独立的内存空间，其虚拟地址是用虚拟地址池来管理的 页表，让进程拥有独立的内存空间 复制出来的进程需要加入到就绪队列中。 实现read系统调用,putchar(输出一个字符), clear(清屏） 实现系统的交互思路：需要首先获取键盘的输入，然后分析命令，进而采取相应的行动。 /* 从文件描述符fd指向的文件中读取count个字节到buf,若成功则返回读出的字节数,到文件尾则返回-1 */ int32_t sys_read(int32_t fd, void* buf, uint32_t count) { ASSERT(buf != NULL); int32_t ret = -1; if (fd 标准输入stdin, 然后不断的获取键盘输入缓冲区的内容 putchar, clear都能通过操作显存实现，可以直接采用汇编，操作相应的屏幕相关的内存地址 简单的shel -- 获取键盘输入 读入键盘缓冲区的内容 /* 从键盘缓冲区中最多读入count个字节到buf。*/ static void readline(char* buf, int32_t count) { assert(buf != NULL && count > 0); char* pos = buf; while (read(stdin_no, pos, 1) != -1 && (pos - buf) 简单的shel -- 解析键盘输入 就是识别命令，如下面的，需要根据具体命令判断参数个数，类型之类的 ls ls - l pwd cd dir1 也需要实现解析路径(绝对路径和相对路径) shell实现ls, cd ,mkdir，pwd等命令 例如pwd命令的实现 /* pwd命令的内建函数 */ void buildin_pwd(uint32_t argc, char** argv UNUSED) { if (argc != 1) { printf(\"pwd: no argument support!\\n\"); return; } else { if (NULL != getcwd(final_path, MAX_PATH_LEN)) { printf(\"%s\\n\", final_path); } else { printf(\"pwd: get current work directory failed.\\n\"); } } } char* argv[MAX_ARG_NR]; // argv为全局变量，为了以后exec的程序可访问参数 int32_t argc = -1; /* 简单的shell */ void my_shell(void) { cwd_cache[0] = '/'; while (1) { print_prompt(); memset(final_path, 0, MAX_PATH_LEN); memset(cmd_line, 0, MAX_PATH_LEN); readline(cmd_line, MAX_PATH_LEN); if (cmd_line[0] == 0) { // 若只键入了一个回车 continue; } argc = -1; argc = cmd_parse(cmd_line, argv, ' '); if (argc == -1) { printf(\"num of arguments exceed %d\\n\", MAX_ARG_NR); continue; } if (!strcmp(\"ls\", argv[0])) { buildin_ls(argc, argv); } else if (!strcmp(\"cd\", argv[0])) { if (buildin_cd(argc, argv) != NULL) { memset(cwd_cache, 0, MAX_PATH_LEN); strcpy(cwd_cache, final_path); } } else if (!strcmp(\"pwd\", argv[0])) { buildin_pwd(argc, argv); } else if (!strcmp(\"ps\", argv[0])) { buildin_ps(argc, argv); } else if (!strcmp(\"clear\", argv[0])) { buildin_clear(argc, argv); } else if (!strcmp(\"mkdir\", argv[0])){ buildin_mkdir(argc, argv); } else if (!strcmp(\"rmdir\", argv[0])){ buildin_rmdir(argc, argv); } else if (!strcmp(\"rm\", argv[0])) { buildin_rm(argc, argv); } else { printf(\"external command\\n\"); } } panic(\"my_shell: should not be here\"); } 运行截图 Copyright @doctording all right reserved，powered by Gitbookupdate at: 2020-08-02 18:25:53 "}}